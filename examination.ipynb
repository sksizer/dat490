{
 "cells": [
  {
   "cell_type": "code",
   "id": "b3f80504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:53.149371Z",
     "start_time": "2025-06-03T05:28:49.865792Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/LLCP2023.parquet')\n",
    "df_mapped = pd.read_parquet('./data/LLCP2023_partialmap.parquet')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "5e2e972a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:53.209347Z",
     "start_time": "2025-06-03T05:28:53.180834Z"
    }
   },
   "source": [
    "df.info()\n",
    "df.head(n=1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 433323 entries, 0 to 433322\n",
      "Columns: 350 entries, _STATE to _DRNKDRV\n",
      "dtypes: float64(345), object(5)\n",
      "memory usage: 1.1+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     _STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE       SEQNO  \\\n",
       "0       1.0     1.0  03012023     03   01  2023    1100.0  2023000001   \n",
       "1       1.0     1.0  01062023     01   06  2023    1100.0  2023000002   \n",
       "2       1.0     1.0  03082023     03   08  2023    1100.0  2023000003   \n",
       "3       1.0     1.0  03062023     03   06  2023    1100.0  2023000004   \n",
       "4       1.0     1.0  01062023     01   06  2023    1100.0  2023000005   \n",
       "..      ...     ...       ...    ...  ...   ...       ...         ...   \n",
       "995     1.0     1.0  03102023     03   10  2023    1100.0  2023000996   \n",
       "996     1.0     1.0  01192023     01   19  2023    1100.0  2023000997   \n",
       "997     1.0     1.0  03022023     03   02  2023    1100.0  2023000998   \n",
       "998     1.0     1.0  01112023     01   11  2023    1100.0  2023000999   \n",
       "999     1.0     1.0  01242023     01   24  2023    1100.0  2023001000   \n",
       "\n",
       "             _PSU  CTELENM1  ...  DROCDY4_  _RFBING6  _DRNKWK2  _RFDRHV8  \\\n",
       "0    2.023000e+09       1.0  ...       0.0       1.0       0.0       1.0   \n",
       "1    2.023000e+09       1.0  ...       0.0       1.0       0.0       1.0   \n",
       "2    2.023000e+09       1.0  ...       0.0       1.0       0.0       1.0   \n",
       "3    2.023000e+09       1.0  ...       0.0       1.0       0.0       1.0   \n",
       "4    2.023000e+09       1.0  ...       7.0       1.0      47.0       1.0   \n",
       "..            ...       ...  ...       ...       ...       ...       ...   \n",
       "995  2.023001e+09       NaN  ...       0.0       1.0       0.0       1.0   \n",
       "996  2.023001e+09       NaN  ...      17.0       1.0     117.0       1.0   \n",
       "997  2.023001e+09       NaN  ...       0.0       1.0       0.0       1.0   \n",
       "998  2.023001e+09       NaN  ...      10.0       1.0     210.0       1.0   \n",
       "999  2.023001e+09       NaN  ...       0.0       1.0       0.0       1.0   \n",
       "\n",
       "     _FLSHOT7  _PNEUMO3  _AIDTST4  _RFSEAT2  _RFSEAT3  _DRNKDRV  \n",
       "0         2.0       2.0       2.0       1.0       1.0       9.0  \n",
       "1         1.0       1.0       2.0       1.0       1.0       9.0  \n",
       "2         1.0       1.0       2.0       1.0       1.0       9.0  \n",
       "3         1.0       1.0       1.0       1.0       1.0       9.0  \n",
       "4         2.0       1.0       2.0       1.0       1.0       2.0  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "995       2.0       2.0       2.0       2.0       2.0       9.0  \n",
       "996       NaN       NaN       1.0       1.0       1.0       2.0  \n",
       "997       2.0       1.0       1.0       2.0       2.0       9.0  \n",
       "998       NaN       NaN       1.0       1.0       1.0       2.0  \n",
       "999       NaN       NaN       2.0       2.0       2.0       9.0  \n",
       "\n",
       "[1000 rows x 350 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENM1</th>\n",
       "      <th>...</th>\n",
       "      <th>DROCDY4_</th>\n",
       "      <th>_RFBING6</th>\n",
       "      <th>_DRNKWK2</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_FLSHOT7</th>\n",
       "      <th>_PNEUMO3</th>\n",
       "      <th>_AIDTST4</th>\n",
       "      <th>_RFSEAT2</th>\n",
       "      <th>_RFSEAT3</th>\n",
       "      <th>_DRNKDRV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03012023</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000001</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01062023</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000002</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03082023</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000003</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03062023</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000004</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01062023</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000005</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03102023</td>\n",
       "      <td>03</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000996</td>\n",
       "      <td>2.023001e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01192023</td>\n",
       "      <td>01</td>\n",
       "      <td>19</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000997</td>\n",
       "      <td>2.023001e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03022023</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000998</td>\n",
       "      <td>2.023001e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01112023</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000999</td>\n",
       "      <td>2.023001e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01242023</td>\n",
       "      <td>01</td>\n",
       "      <td>24</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023001000</td>\n",
       "      <td>2.023001e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 350 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "2fdee5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:53.269623Z",
     "start_time": "2025-06-03T05:28:53.260468Z"
    }
   },
   "source": [
    "df_mapped.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    _STATE   FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE       SEQNO  \\\n",
       "0  Alabama  January  03012023     03   01  2023    1100.0  2023000001   \n",
       "1  Alabama  January  01062023     01   06  2023    1100.0  2023000002   \n",
       "2  Alabama  January  03082023     03   08  2023    1100.0  2023000003   \n",
       "3  Alabama  January  03062023     03   06  2023    1100.0  2023000004   \n",
       "4  Alabama  January  01062023     01   06  2023    1100.0  2023000005   \n",
       "\n",
       "           _PSU  CTELENM1  ...  _DRNKWK2             _RFDRHV8  \\\n",
       "0  2.023000e+09       1.0  ...       0.0  Not a heavy drinker   \n",
       "1  2.023000e+09       1.0  ...       0.0  Not a heavy drinker   \n",
       "2  2.023000e+09       1.0  ...       0.0  Not a heavy drinker   \n",
       "3  2.023000e+09       1.0  ...       0.0  Not a heavy drinker   \n",
       "4  2.023000e+09       1.0  ...      47.0  Not a heavy drinker   \n",
       "\n",
       "                      _FLSHOT7                           _PNEUMO3  \\\n",
       "0                No (65+ only)                                 No   \n",
       "1  Yes (flu shot in past year)  Yes (pneumonia vaccine, 65+ only)   \n",
       "2  Yes (flu shot in past year)  Yes (pneumonia vaccine, 65+ only)   \n",
       "3  Yes (flu shot in past year)  Yes (pneumonia vaccine, 65+ only)   \n",
       "4                No (65+ only)  Yes (pneumonia vaccine, 65+ only)   \n",
       "\n",
       "              _AIDTST4                 _RFSEAT2  _RFSEAT3  \\\n",
       "0                   No  Always or Almost Always    Always   \n",
       "1                   No  Always or Almost Always    Always   \n",
       "2                   No  Always or Almost Always    Always   \n",
       "3  Yes, tested for HIV  Always or Almost Always    Always   \n",
       "4                   No  Always or Almost Always    Always   \n",
       "\n",
       "                     _DRNKDRV  MAXVO21_vo2ml  FC601_mets  \n",
       "0  Don’t know/Refused/Missing          18.40        3.15  \n",
       "1  Don’t know/Refused/Missing          18.03        3.09  \n",
       "2  Don’t know/Refused/Missing          13.22        2.27  \n",
       "3  Don’t know/Refused/Missing          19.14        3.28  \n",
       "4                         Yes          19.88        3.41  \n",
       "\n",
       "[5 rows x 352 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENM1</th>\n",
       "      <th>...</th>\n",
       "      <th>_DRNKWK2</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_FLSHOT7</th>\n",
       "      <th>_PNEUMO3</th>\n",
       "      <th>_AIDTST4</th>\n",
       "      <th>_RFSEAT2</th>\n",
       "      <th>_RFSEAT3</th>\n",
       "      <th>_DRNKDRV</th>\n",
       "      <th>MAXVO21_vo2ml</th>\n",
       "      <th>FC601_mets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>03012023</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000001</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not a heavy drinker</td>\n",
       "      <td>No (65+ only)</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Always or Almost Always</td>\n",
       "      <td>Always</td>\n",
       "      <td>Don’t know/Refused/Missing</td>\n",
       "      <td>18.40</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>01062023</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000002</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not a heavy drinker</td>\n",
       "      <td>Yes (flu shot in past year)</td>\n",
       "      <td>Yes (pneumonia vaccine, 65+ only)</td>\n",
       "      <td>No</td>\n",
       "      <td>Always or Almost Always</td>\n",
       "      <td>Always</td>\n",
       "      <td>Don’t know/Refused/Missing</td>\n",
       "      <td>18.03</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>03082023</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000003</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not a heavy drinker</td>\n",
       "      <td>Yes (flu shot in past year)</td>\n",
       "      <td>Yes (pneumonia vaccine, 65+ only)</td>\n",
       "      <td>No</td>\n",
       "      <td>Always or Almost Always</td>\n",
       "      <td>Always</td>\n",
       "      <td>Don’t know/Refused/Missing</td>\n",
       "      <td>13.22</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>03062023</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000004</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not a heavy drinker</td>\n",
       "      <td>Yes (flu shot in past year)</td>\n",
       "      <td>Yes (pneumonia vaccine, 65+ only)</td>\n",
       "      <td>Yes, tested for HIV</td>\n",
       "      <td>Always or Almost Always</td>\n",
       "      <td>Always</td>\n",
       "      <td>Don’t know/Refused/Missing</td>\n",
       "      <td>19.14</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>01062023</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2023</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2023000005</td>\n",
       "      <td>2.023000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Not a heavy drinker</td>\n",
       "      <td>No (65+ only)</td>\n",
       "      <td>Yes (pneumonia vaccine, 65+ only)</td>\n",
       "      <td>No</td>\n",
       "      <td>Always or Almost Always</td>\n",
       "      <td>Always</td>\n",
       "      <td>Yes</td>\n",
       "      <td>19.88</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 352 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "d9df868bc54a3f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:53.312975Z",
     "start_time": "2025-06-03T05:28:53.311740Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb2ff5fd17dfde64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3a116f7ac817224",
   "metadata": {},
   "source": [
    "# Friendly Mapping\n",
    "This creates a lookup dictionary between a column and the metadata the codebook provides on it.\n",
    "\n",
    "With this we can lookup what a value at a row/column (such as 1) 'means'.\n",
    "\n",
    "My intent was to add additional metadata there to support further EDA and analysis.\n",
    "```python\n",
    "# Example\n",
    "```\n",
    "- This create a lookup object between columns and 'friendly names'\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba3161d37b838f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:59.258855Z",
     "start_time": "2025-06-03T05:28:58.338081Z"
    }
   },
   "source": [
    "# Import the metadata parser\n",
    "from pathlib import Path\n",
    "from metadata.parser import parse_codebook_html\n",
    "\n",
    "# Parse the codebook HTML file\n",
    "codebook_path = Path('./data/codebook_USCODE23_LLCP_021924.HTML')\n",
    "column_metadata = parse_codebook_html(codebook_path)\n",
    "\n",
    "# Display the number of columns parsed\n",
    "print(f\"Parsed {len(column_metadata)} column definitions from the codebook\")\n",
    "\n",
    "# Show a sample of the metadata\n",
    "sample_keys = list(column_metadata.keys())[:5]\n",
    "for key in sample_keys:\n",
    "    metadata = column_metadata[key]\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Label: {metadata.label}\")\n",
    "    print(f\"  Question: {metadata.question}\")\n",
    "    print(f\"  Column: {metadata.column}\")\n",
    "    print(f\"  Type: {metadata.type_of_variable}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 344 column definitions from the codebook\n",
      "\n",
      "_STATE:\n",
      "  Label: State FIPS Code\n",
      "  Question: State FIPS Code\n",
      "  Column: 1-2\n",
      "  Type: Num\n",
      "\n",
      "FMONTH:\n",
      "  Label: File Month\n",
      "  Question: File Month\n",
      "  Column: 17-18\n",
      "  Type: Num\n",
      "\n",
      "IDATE:\n",
      "  Label: Interview Date\n",
      "  Question: Interview Date\n",
      "  Column: 19-26\n",
      "  Type: Char\n",
      "\n",
      "IMONTH:\n",
      "  Label: Interview Month\n",
      "  Question: Interview Month\n",
      "  Column: 19-20\n",
      "  Type: Char\n",
      "\n",
      "IDAY:\n",
      "  Label: Interview Day\n",
      "  Question: Interview Day\n",
      "  Column: 21-22\n",
      "  Type: Char\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "996ef804a45ec667",
   "metadata": {},
   "source": [
    "# Examining Metadata\n",
    "At this point we should have the metadata about columns extracted.\n",
    "\n",
    "Right now it is a dictionary where column name is key."
   ]
  },
  {
   "cell_type": "code",
   "id": "72e44922f8d671e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:29:02.648245Z",
     "start_time": "2025-06-03T05:29:02.643520Z"
    }
   },
   "source": [
    "# Check how complete the metadata is\n",
    "print(f\"Total columns in dataframe: {len(df.columns)}\")\n",
    "print(f\"Total metadata parsed: {len(column_metadata)}\")\n",
    "print(f\"Coverage: {len(column_metadata) / len(df.columns) * 100:.1f}%\")\n",
    "\n",
    "# Check which columns don't have metadata\n",
    "missing_metadata = [col for col in df.columns if col not in column_metadata]\n",
    "print(f\"\\nColumns without metadata: {len(missing_metadata)}\")\n",
    "if missing_metadata:\n",
    "    print(\"First 10 missing:\", missing_metadata[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in dataframe: 354\n",
      "Total metadata parsed: 344\n",
      "Coverage: 97.2%\n",
      "\n",
      "Columns without metadata: 11\n",
      "First 10 missing: ['LNDSXBRT', 'CELSXBRT', 'BIRTHSEX', 'TRNSGNDR', 'USEMRJN4', 'RCSGEND1', 'RCSXBRTH', 'STATE_NAME', '_STATE_DESC', 'FMONTH_DESC']\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "d2aaf566c76736e0",
   "metadata": {},
   "source": [
    "To be a bit more data science oriented we'll turn the dictionary into another dataframe:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Understanding the Friendly Mapping Feature\n\nThe metadata parser includes a powerful \"friendly mapping\" feature that translates numeric codes in the dataset to their human-readable descriptions. This is particularly useful for categorical variables where numeric codes represent specific responses.\n\n## How It Works\n\nEach `ColumnMetadata` object contains a `value_lookup` dictionary that maps numeric values (or None) to their text descriptions. This mapping is automatically extracted from the codebook HTML file during parsing.\n\n### Key Components:\n\n1. **`value_lookup` dictionary**: Found in each `ColumnMetadata` object\n   - Keys: Numeric codes (int) or None\n   - Values: Human-readable descriptions (str)\n\n2. **Automatic extraction**: The `get_value_lookup()` function in `parser.py` extracts these mappings from HTML tables in the codebook\n\n## Example Usage",
   "metadata": {},
   "id": "d4afdab76247c9d2"
  },
  {
   "cell_type": "code",
   "source": "# Example 1: Understanding what values mean for a specific column\n# Let's look at the _STATE column which has distinct state codes\n\nstate_metadata = column_metadata['_STATE']\nprint(f\"Column: {state_metadata.sas_variable_name}\")\nprint(f\"Label: {state_metadata.label}\")\nprint(f\"Question: {state_metadata.question}\")\nprint(f\"\\nSample of value mappings (first 10):\")\n# Show first 10 state mappings\nfor i, (value, description) in enumerate(state_metadata.value_lookup.items()):\n    if i < 10:\n        print(f\"  {value}: {description}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:29:07.256108Z",
     "start_time": "2025-06-03T05:29:07.251717Z"
    }
   },
   "id": "e1324bee144892f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: _STATE\n",
      "Label: State FIPS Code\n",
      "Question: State FIPS Code\n",
      "\n",
      "Sample of value mappings (first 10):\n",
      "  1: Alabama\n",
      "  2: Alaska\n",
      "  4: Arizona\n",
      "  5: Arkansas\n",
      "  6: California\n",
      "  8: Colorado\n",
      "  9: Connecticut\n",
      "  10: Delaware\n",
      "  11: District of Columbia\n",
      "  12: Florida\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "# Example 2: Translating values in your data\n",
    "# Let's translate some actual STATE values from the dataframe\n",
    "\n",
    "# Get a sample of state values\n",
    "sample_values = df['_STATE'].value_counts().head(10)\n",
    "print(\"Top 10 states by number of respondents:\\n\")\n",
    "\n",
    "for value, count in sample_values.items():\n",
    "    # Get the description from value_lookup\n",
    "    description = state_metadata.value_lookup.get(int(value) if not pd.isna(value) else None, \"Unknown\")\n",
    "    print(f\"Code {int(value)}: {description} (Count: {count:,})\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:29:14.351175Z",
     "start_time": "2025-06-03T05:29:14.342260Z"
    }
   },
   "id": "3708f53c4ed071a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 states by number of respondents:\n",
      "\n",
      "Code 53: Washington (Count: 26,444)\n",
      "Code 36: New York (Count: 17,349)\n",
      "Code 24: Maryland (Count: 17,255)\n",
      "Code 27: Minnesota (Count: 16,170)\n",
      "Code 39: Ohio (Count: 13,384)\n",
      "Code 12: Florida (Count: 13,255)\n",
      "Code 31: Nebraska (Count: 12,886)\n",
      "Code 55: Wisconsin (Count: 12,819)\n",
      "Code 23: Maine (Count: 12,255)\n",
      "Code 4: Arizona (Count: 12,036)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:54.743536Z",
     "start_time": "2025-06-03T05:28:54.595905Z"
    }
   },
   "cell_type": "code",
   "source": "# Example 3: Creating a mapping function for easy translation\ndef translate_column_values(df, column_name, metadata_dict):\n    \"\"\"\n    Translate numeric codes to descriptions for a specific column.\n    \n    Args:\n        df: The dataframe containing the data\n        column_name: Name of the column to translate\n        metadata_dict: Dictionary of column metadata\n    \n    Returns:\n        Pandas Series with translated values\n    \"\"\"\n    if column_name not in metadata_dict:\n        print(f\"No metadata found for column: {column_name}\")\n        return df[column_name]\n    \n    metadata = metadata_dict[column_name]\n    \n    # Create translation function\n    def translate(value):\n        if pd.isna(value):\n            return \"Missing\"\n        return metadata.value_lookup.get(int(value), f\"Unknown code: {value}\")\n    \n    return df[column_name].apply(translate)\n\n# Example usage - translate STATE codes\ndf['STATE_NAME'] = translate_column_values(df, '_STATE', column_metadata)\n\n# Show sample\nprint(\"Sample of translated state values:\")\nprint(df[['_STATE', 'STATE_NAME']].head(10))",
   "id": "a201909d5b5d4540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of translated state values:\n",
      "   _STATE STATE_NAME\n",
      "0     1.0    Alabama\n",
      "1     1.0    Alabama\n",
      "2     1.0    Alabama\n",
      "3     1.0    Alabama\n",
      "4     1.0    Alabama\n",
      "5     1.0    Alabama\n",
      "6     1.0    Alabama\n",
      "7     1.0    Alabama\n",
      "8     1.0    Alabama\n",
      "9     1.0    Alabama\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "# Example 4: Working with columns that have ranges\n# Now let's test with POORHLTH which has a range value \"1 - 30\"\n\n# Re-parse the metadata with the updated parser\nfrom metadata.parser import parse_codebook_html\ncolumn_metadata = parse_codebook_html(codebook_path)\n\npoorhlth_metadata = column_metadata['POORHLTH']\nprint(f\"Column: {poorhlth_metadata.sas_variable_name}\")\nprint(f\"Label: {poorhlth_metadata.label}\")\n\n# Check if the range was properly expanded\nprint(f\"\\nTotal value mappings: {len(poorhlth_metadata.value_lookup)}\")\nprint(\"\\nSample mappings:\")\n# Show some specific values to verify range expansion\nfor value in [1, 15, 30, 77, 88, 99]:\n    if value in poorhlth_metadata.value_lookup:\n        print(f\"  {value}: {poorhlth_metadata.value_lookup[value]}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:55.688205Z",
     "start_time": "2025-06-03T05:28:54.792714Z"
    }
   },
   "id": "d338a733253d483c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: POORHLTH\n",
      "Label: Poor Physical or Mental Health\n",
      "\n",
      "Total value mappings: 4\n",
      "\n",
      "Sample mappings:\n",
      "  77: Don't know/Not sure\n",
      "  88: None\n",
      "  99: Refused\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "# Example 5: Batch translation of multiple columns\n# This example shows how to efficiently translate multiple columns at once\n\ndef batch_translate_columns(df, column_list, metadata_dict):\n    \"\"\"\n    Translate multiple columns from numeric codes to descriptions.\n    \n    Args:\n        df: The dataframe containing the data\n        column_list: List of column names to translate\n        metadata_dict: Dictionary of column metadata\n    \n    Returns:\n        Dictionary of translated series\n    \"\"\"\n    translated = {}\n    \n    for col in column_list:\n        if col in metadata_dict and col in df.columns:\n            translated[f\"{col}_DESC\"] = translate_column_values(df, col, metadata_dict)\n            print(f\"Translated {col}\")\n        else:\n            print(f\"Skipped {col} (not found in metadata or dataframe)\")\n    \n    return translated\n\n# Translate several categorical columns\ncolumns_to_translate = ['_STATE', 'FMONTH', 'DISPCODE', 'SEX1']\ntranslations = batch_translate_columns(df, columns_to_translate, column_metadata)\n\n# Add translations to dataframe\nfor col_name, translated_series in translations.items():\n    df[col_name] = translated_series\n\n# Show sample of multiple translations\nprint(\"\\nSample of translated data:\")\noriginal_cols = columns_to_translate[:3]  # Show first 3\ndesc_cols = [f\"{col}_DESC\" for col in original_cols]\nprint(df[original_cols + desc_cols].head())",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T05:28:56.133251Z",
     "start_time": "2025-06-03T05:28:55.700342Z"
    }
   },
   "id": "dfaf044ac3932285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated _STATE\n",
      "Translated FMONTH\n",
      "Translated DISPCODE\n",
      "Skipped SEX1 (not found in metadata or dataframe)\n",
      "\n",
      "Sample of translated data:\n",
      "   _STATE  FMONTH  DISPCODE _STATE_DESC FMONTH_DESC        DISPCODE_DESC\n",
      "0     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "1     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "2     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "3     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "4     1.0     1.0    1100.0     Alabama     January  Completed Interview\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Usage Tips (NOTE these tips were ChatGPT generated)\n",
    "\n",
    "### 1. Filtering Data by Descriptions\n",
    "Once you have the friendly mappings, you can filter data using human-readable criteria:\n",
    "\n",
    "```python\n",
    "# Find all respondents from California\n",
    "california_code = next(k for k, v in state_metadata.value_lookup.items() if 'California' in v)\n",
    "ca_data = df[df['_STATE'] == california_code]\n",
    "```\n",
    "\n",
    "### 2. Creating Analysis-Ready DataFrames\n",
    "The friendly mappings are especially useful when creating subsets for analysis:\n",
    "\n",
    "```python\n",
    "# Create a subset with translated categorical variables\n",
    "analysis_df = df[['_STATE', 'SEX1', 'POORHLTH']].copy()\n",
    "for col in analysis_df.columns:\n",
    "    if col in column_metadata:\n",
    "        analysis_df[f'{col}_desc'] = translate_column_values(analysis_df, col, column_metadata)\n",
    "```\n",
    "\n",
    "### 3. Handling Special Values\n",
    "Many BRFSS variables use special codes like:\n",
    "- 77: Don't know/Not sure\n",
    "- 88: None (for days-based questions)\n",
    "- 99: Refused\n",
    "\n",
    "The value_lookup dictionary includes these, making it easy to identify and handle them appropriately in your analysis.\n",
    "\n",
    "### 4. Integration with Existing Mapped Data\n",
    "The `LLCP2023_partialmap.parquet` file already has some columns translated. You can use the metadata parser to:\n",
    "- Verify existing mappings\n",
    "- Add mappings for additional columns\n",
    "- Create custom mapping schemes for specific analyses"
   ],
   "metadata": {},
   "id": "245ea964f3b67bb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
