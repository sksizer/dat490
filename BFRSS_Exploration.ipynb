{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YMzEMIm7Iuw6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sksizer/dat490/blob/main/BFRSS_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "- check env\n",
        "- set and test paths for data"
      ],
      "metadata": {
        "id": "YMzEMIm7Iuw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython import get_ipython\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def is_colab():\n",
        "    return 'google.colab' in str(get_ipython())\n",
        "\n",
        "if is_colab() and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if is_colab():\n",
        "    BFRSS_DATA_PATH = '/content/drive/MyDrive/DAT490/data/LLCP2023.parquet'\n",
        "    BFRSS_CODEBOOK_PATH = '/content/drive/MyDrive/DAT490/data/codebook_USCODE23_LLCP_021924.HTML'\n",
        "else:\n",
        "    BFRSS_CODEBOOK_PATH = './data/'\n",
        "    BFRSS_DATA_PATH = './data/'\n",
        "\n",
        "if not os.path.exists(BFRSS_DATA_PATH):\n",
        "    raise Exception(f\"Data path ${BFRSS_DATA_PATH} does not exist\")\n",
        "\n",
        "if not os.path.exists(BFRSS_CODEBOOK_PATH):\n",
        "    raise Exception(f\"Codebook path ${BFRSS_CODEBOOK_PATH} does not exist\")\n",
        "logger.info('Environment setup complete')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "pVJYYPAYIT8C",
        "outputId": "9db82052-827b-47e6-d144-aafed9ada0a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a17e839fe33b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data and Metadata\n",
        "- creates starting DF `bfrss_raw_df` from BFRSS data\n",
        "- extract metadata: parses [Codebook](https://github.com/sksizer/dat490/blob/main/data/codebook_USCODE23_LLCP_021924.HTML) into a dictionary that uses columns as keys:\n",
        "  ```\n",
        "  bfrss_metadata\n",
        "  # to get the metadata for a column:\n",
        "  bfrss_metadata['COLUMN1']\n",
        "\n",
        "  # It also has value to value descriptions such as:\n",
        "  bfrss_metadata['COLUMN1'].value_lookup[1] # will return something like 'Number of times worked out in last week'\n",
        "  ```"
      ],
      "metadata": {
        "id": "7gcIaBDZpH8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eckrUOR1ilCW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "bfrss_raw_df = pd.read_parquet(BFRSS_DATA_PATH)\n",
        "bfrss_raw_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "from bs4 import BeautifulSoup, PageElement\n",
        "\n",
        "\n",
        "class ColumnMetadata(BaseModel):\n",
        "    computed: bool\n",
        "    label: str\n",
        "    sas_variable_name: str\n",
        "    section_name: Optional[str] = None\n",
        "    section_number: Optional[int] = None\n",
        "    module_number: Optional[int] = None  # Added module_number field\n",
        "    question_number: Optional[int] = None\n",
        "    column: Optional[str] = None  # Can be a range like \"1-2\" or single number\n",
        "    type_of_variable: Optional[str] = None  # \"Num\" or \"Char\"\n",
        "    question_prologue: Optional[str] = None\n",
        "    question: Optional[str] = None\n",
        "    value_lookup: dict[None | int, str] # This is a dictionary that returns the textual\n",
        "\n",
        "\n",
        "def get_value_lookup(table:PageElement) -> Dict[None | int, str]:\n",
        "    \"\"\"\n",
        "    Given one of the branch table objects, we can extract out in a fairly\n",
        "    simple manner all the possible values for the target column\n",
        "\n",
        "    Simplified table structure example:\n",
        "    <table>\n",
        "    <tbody>\n",
        "    <tr>\n",
        "    <td>value</td> (which might be a single int value, blank or could be a range\n",
        "    <td>Value description\n",
        "    </tr>\n",
        "    </tbody>\n",
        "    </table>\n",
        "\n",
        "    :param table:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    value_dict : Dict[None | int, str] = {} # Stores the value to value description\n",
        "\n",
        "    for tr in table.find('tbody').find_all('tr'):\n",
        "        cells = tr.find_all('td')\n",
        "        if len(cells) < 2:\n",
        "            continue\n",
        "\n",
        "        value_text = cells[0].text.strip()\n",
        "        description = cells[1].text.strip()\n",
        "\n",
        "        # Check if the value is actually a range such as \"1 - 30\" or \"1-30\"\n",
        "        range_match = re.match(r'^(\\d+)\\s*[-â€“]\\s*(\\d+)$', value_text)\n",
        "        if range_match:\n",
        "            start = int(range_match.group(1))\n",
        "            end = int(range_match.group(2))\n",
        "            # Add each value in the range\n",
        "            # This is kind of ugly because we are creating some value lookups\n",
        "            # that have thousands of values...a function would be better but I\n",
        "            # was trying to keep the metadata 'pure' data\n",
        "            for i in range(start, end + 1):\n",
        "                value_dict[i] = description\n",
        "        else:\n",
        "            # Try to parse as single integer\n",
        "            try:\n",
        "                value = int(value_text)\n",
        "                value_dict[value] = description\n",
        "            except:\n",
        "                # If not a number, store as None\n",
        "                value_dict[None] = description\n",
        "\n",
        "    return value_dict\n",
        "\n",
        "def parse_codebook_html(html_path: Path) -> Dict[str, ColumnMetadata]:\n",
        "    \"\"\"\n",
        "    Parse the BRFSS codebook HTML file and extract column metadata.\n",
        "\n",
        "    Args:\n",
        "        html_path: Path to the HTML codebook file\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping SAS variable names to ColumnMetadata objects\n",
        "    \"\"\"\n",
        "    with open(html_path, 'r', encoding='windows-1252') as f:\n",
        "        html_content = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Find all div elements with class \"branch\"\n",
        "    branches = soup.find_all('div', class_='branch')\n",
        "\n",
        "    # The first one is the Codebook header table which we don't want\n",
        "    branches = branches[1:]\n",
        "\n",
        "    metadata_dict = {}\n",
        "\n",
        "    for branch in branches:\n",
        "        # Find the table with summary=\"Procedure Report: Report\"\n",
        "        table = branch.find('table', attrs={'summary': 'Procedure Report: Report'})\n",
        "        if not table:\n",
        "            continue\n",
        "\n",
        "        # Find the first td in the thead > tr\n",
        "        thead = table.find('thead')\n",
        "        if not thead:\n",
        "            continue\n",
        "\n",
        "        first_tr = thead.find('tr')\n",
        "        if not first_tr:\n",
        "            continue\n",
        "\n",
        "        # Find td with metadata content - may not have all classes\n",
        "        metadata_cell = None\n",
        "        for td in first_tr.find_all('td'):\n",
        "            text = td.get_text()\n",
        "            if text:\n",
        "                # Clean text before checking\n",
        "                text_clean = text.replace('\\xa0', ' ')\n",
        "                if 'Label:' in text_clean and 'SAS Variable Name:' in text_clean:\n",
        "                    metadata_cell = td\n",
        "                    break\n",
        "\n",
        "        if not metadata_cell:\n",
        "            continue\n",
        "\n",
        "        cell_text = metadata_cell.get_text()\n",
        "\n",
        "        # Check if this cell contains column metadata by looking for key fields\n",
        "        try:\n",
        "            # Extract fields using regex - handle non-breaking spaces\n",
        "            cell_text = cell_text.replace('\\xa0', ' ')  # Replace non-breaking spaces\n",
        "\n",
        "            label_match = re.search(r'Label:\\s*(.+?)(?=Section\\s*Name:|Core\\s*Section\\s*Number:|Module\\s*Number:|$)', cell_text, re.DOTALL)\n",
        "            section_name_match = re.search(r'Section\\s*Name:\\s*(.+?)(?=Core\\s*Section\\s*Number:|Section\\s*Number:|Module\\s*Number:|Question\\s*Number:|$)', cell_text, re.DOTALL)\n",
        "            # Handle both \"Core Section Number\" and \"Section Number\"\n",
        "            section_number_match = re.search(r'(?:Core\\s*)?Section\\s*Number:\\s*(\\d+)', cell_text)\n",
        "            # Handle \"Module Number\"\n",
        "            module_number_match = re.search(r'Module\\s*Number:\\s*(\\d+)', cell_text)\n",
        "            question_number_match = re.search(r'Question\\s*Number:\\s*(\\d+)', cell_text)\n",
        "            column_match = re.search(r'Column:\\s*(.+?)(?=Type\\s*of\\s*Variable:|$)', cell_text, re.DOTALL)\n",
        "            type_match = re.search(r'Type\\s*of\\s*Variable:\\s*(.+?)(?=SAS\\s*Variable\\s*Name:|$)', cell_text, re.DOTALL)\n",
        "            sas_name_match = re.search(r'SAS\\s*Variable\\s*Name:\\s*(.+?)(?=Question\\s*Prologue:|Question:|$)', cell_text, re.DOTALL)\n",
        "            prologue_match = re.search(r'Question\\s*Prologue:\\s*(.+?)(?=Question:|$)', cell_text, re.DOTALL)\n",
        "            question_match = re.search(r'Question:\\s*(.+?)$', cell_text, re.DOTALL)\n",
        "\n",
        "            # Only require label and SAS variable name\n",
        "            if label_match and sas_name_match:\n",
        "\n",
        "                # Clean up the extracted values\n",
        "                label = label_match.group(1).strip()\n",
        "                sas_variable_name = sas_name_match.group(1).strip()\n",
        "\n",
        "                # Extract optional fields\n",
        "                section_name = section_name_match.group(1).strip() if section_name_match else None\n",
        "                section_number = int(section_number_match.group(1)) if section_number_match else None\n",
        "                module_number = int(module_number_match.group(1)) if module_number_match else None\n",
        "                question_number = int(question_number_match.group(1)) if question_number_match else None\n",
        "                column = column_match.group(1).strip() if column_match else None\n",
        "                type_of_variable = type_match.group(1).strip() if type_match else None\n",
        "                question_prologue = prologue_match.group(1).strip() if prologue_match else None\n",
        "                question = question_match.group(1).strip() if question_match else None\n",
        "\n",
        "                # Remove any extra whitespace or newlines\n",
        "                if question_prologue and not question_prologue:\n",
        "                    question_prologue = None\n",
        "\n",
        "                # Create ColumnMetadata object\n",
        "                metadata = ColumnMetadata(\n",
        "                    label=label,\n",
        "                    sas_variable_name=sas_variable_name,\n",
        "                    section_name=section_name,\n",
        "                    section_number=section_number,\n",
        "                    module_number=module_number,\n",
        "                    question_number=question_number,\n",
        "                    column=column,\n",
        "                    type_of_variable=type_of_variable,\n",
        "                    question_prologue=question_prologue,\n",
        "                    question=question,\n",
        "                    value_lookup=get_value_lookup(table),\n",
        "                    computed= True if section_name == 'Calculated Variables' or section_name == 'Calculated Race Variables' else False\n",
        "                )\n",
        "\n",
        "                metadata_dict[sas_variable_name] = metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            # Skip cells that don't parse correctly but show problems\n",
        "            print(e)\n",
        "\n",
        "    return metadata_dict\n",
        "\n",
        "\n",
        "bfrss_metadata = parse_codebook_html(BFRSS_CODEBOOK_PATH)"
      ],
      "metadata": {
        "id": "xYWEooJMAwr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of columns parsed\n",
        "print(f\"Parsed {len(bfrss_metadata)} column definitions from the codebook\")\n",
        "\n",
        "# Show a sample of the metadata\n",
        "sample_keys = list(bfrss_metadata.keys())[:5]\n",
        "for key in sample_keys:\n",
        "    metadata = bfrss_metadata[key]\n",
        "    print(f\"\\n{key}:\")\n",
        "    print(f\"  Label: {metadata.label}\")\n",
        "    print(f\"  Question: {metadata.question}\")\n",
        "    print(f\"  Column: {metadata.column}\")\n",
        "    print(f\"  Type: {metadata.type_of_variable}\")\n",
        "    print(f\"  Computed: {metadata.computed}\")\n",
        "    print(f\"  Section Name: {metadata.section_name}\")\n",
        "    print(f\"  Section Number: {metadata.section_number}\")\n",
        "    print(f\"  Question Number: {metadata.question_number}\")"
      ],
      "metadata": {
        "id": "PTKxZUFcNlao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata Documentation\n",
        "Notes and examples of the metadata extraction:\n",
        "\n"
      ],
      "metadata": {
        "id": "XgwFJt3YNBjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total columns in dataframe: {len(bfrss_raw_df.columns)}\")\n",
        "print(f\"Total metadata parsed: {len(bfrss_metadata)}\")\n",
        "print(f\"Coverage: {len(bfrss_metadata) / len(bfrss_raw_df.columns) * 100:.1f}%\")\n",
        "\n",
        "# Check which columns don't have metadata\n",
        "missing_metadata = [col for col in bfrss_raw_df.columns if col not in bfrss_metadata]\n",
        "print(f\"\\nColumns without metadata: {len(missing_metadata)}\")\n",
        "if missing_metadata:\n",
        "    print(\"First 10 missing:\", missing_metadata[:10])\n",
        "print(\"Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\")"
      ],
      "metadata": {
        "id": "IGcHPEctN3yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Friendly Mapping Feature\n",
        "(note I generated the following docs and examples with ChatGPT, but I've vetted all of it)\n",
        "\n",
        "The metadata parser includes a powerful \"friendly mapping\" feature that translates numeric codes in the dataset to their human-readable descriptions. This is particularly useful for categorical variables where numeric codes represent specific responses.\n",
        "\n",
        "### How It Works\n",
        "\n",
        "Each `ColumnMetadata` object contains a `value_lookup` dictionary that maps numeric values (or None) to their text descriptions. This mapping is automatically extracted from the codebook HTML file during parsing.\n",
        "\n",
        "#### Key Components:\n",
        "\n",
        "1. **`value_lookup` dictionary**: Found in each `ColumnMetadata` object\n",
        "   - Keys: Numeric codes (int) or None\n",
        "   - Values: Human-readable descriptions (str)\n",
        "\n",
        "2. **Automatic extraction**: The `get_value_lookup()` function in `parser.py` extracts these mappings from HTML tables in the codebook"
      ],
      "metadata": {
        "id": "CUSQ1RmqOssx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Understanding what values mean for a specific column"
      ],
      "metadata": {
        "id": "gODrkHvrTg-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Understanding what values mean for a specific column\n",
        "# Let's look at the _STATE column which has distinct state codes\n",
        "\n",
        "state_metadata = bfrss_metadata['_STATE']\n",
        "print(f\"Column: {state_metadata.sas_variable_name}\")\n",
        "print(f\"Label: {state_metadata.label}\")\n",
        "print(f\"Question: {state_metadata.question}\")\n",
        "print(f\"\\nSample of value mappings (first 10):\")\n",
        "# Show first 10 state mappings\n",
        "for i, (value, description) in enumerate(state_metadata.value_lookup.items()):\n",
        "    if i < 10:\n",
        "        print(f\"  {value}: {description}\")"
      ],
      "metadata": {
        "id": "0rJpt2FIOttO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V21re5obTSh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Translating values in your data"
      ],
      "metadata": {
        "id": "GNl8M6BgTppS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Translating values in your data\n",
        "# Let's translate some actual STATE values from the dataframe\n",
        "\n",
        "# Get a sample of state values\n",
        "sample_values = bfrss_raw_df['_STATE'].value_counts().head(10)\n",
        "print(\"Top 10 states by number of respondents:\\n\")\n",
        "\n",
        "for value, count in sample_values.items():\n",
        "    # Get the description from value_lookup\n",
        "    description = state_metadata.value_lookup.get(int(value) if not pd.isna(value) else None, \"Unknown\")\n",
        "    print(f\"Code {int(value)}: {description} (Count: {count:,})\")"
      ],
      "metadata": {
        "id": "XxFI_rkHPEge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Creating a mapping function for easy translation"
      ],
      "metadata": {
        "id": "CZ2PT79QTvWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Creating a mapping function for easy translation\n",
        "def translate_column_values(df, column_name, metadata_dict):\n",
        "    \"\"\"\n",
        "    Translate numeric codes to descriptions for a specific column.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe containing the data\n",
        "        column_name: Name of the column to translate\n",
        "        metadata_dict: Dictionary of column metadata\n",
        "\n",
        "    Returns:\n",
        "        Pandas Series with translated values\n",
        "    \"\"\"\n",
        "    if column_name not in metadata_dict:\n",
        "        print(f\"No metadata found for column: {column_name}\")\n",
        "        return df[column_name]\n",
        "\n",
        "    metadata = metadata_dict[column_name]\n",
        "\n",
        "    # Create translation function\n",
        "    def translate(value):\n",
        "        if pd.isna(value):\n",
        "            return \"Missing\"\n",
        "        return metadata.value_lookup.get(int(value), f\"Unknown code: {value}\")\n",
        "\n",
        "    return df[column_name].apply(translate)\n",
        "\n",
        "# Example usage - translate STATE codes\n",
        "bfrss_raw_df['STATE_NAME'] = translate_column_values(bfrss_raw_df, '_STATE', bfrss_metadata)\n",
        "\n",
        "# Show sample\n",
        "print(\"Sample of translated state values:\")\n",
        "print(bfrss_raw_df[['_STATE', 'STATE_NAME']].head(10))"
      ],
      "metadata": {
        "id": "3g1Yxo9qO7Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 4: Working with columns that have ranges"
      ],
      "metadata": {
        "id": "AAj4ILpoTzGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: Working with columns that have ranges\n",
        "# Now let's test with POORHLTH which has a range value \"1 - 30\"\n",
        "poorhlth_metadata = bfrss_metadata['POORHLTH']\n",
        "print(f\"Column: {poorhlth_metadata.sas_variable_name}\")\n",
        "print(f\"Label: {poorhlth_metadata.label}\")\n",
        "\n",
        "# Check if the range was properly expanded\n",
        "print(f\"\\nTotal value mappings: {len(poorhlth_metadata.value_lookup)}\")\n",
        "print(\"\\nSample mappings:\")\n",
        "# Show some specific values to verify range expansion\n",
        "for value in [1, 15, 30, 77, 88, 99]:\n",
        "    if value in poorhlth_metadata.value_lookup:\n",
        "        print(f\"  {value}: {poorhlth_metadata.value_lookup[value]}\")"
      ],
      "metadata": {
        "id": "z3GMA7-BPWDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 5: Batch translation of multiple columns"
      ],
      "metadata": {
        "id": "pEdPwWOXT9sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5: Batch translation of multiple columns\n",
        "# This example shows how to efficiently translate multiple columns at once\n",
        "\n",
        "def batch_translate_columns(df, column_list, metadata_dict):\n",
        "    \"\"\"\n",
        "    Translate multiple columns from numeric codes to descriptions.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe containing the data\n",
        "        column_list: List of column names to translate\n",
        "        metadata_dict: Dictionary of column metadata\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of translated series\n",
        "    \"\"\"\n",
        "    translated = {}\n",
        "\n",
        "    for col in column_list:\n",
        "        if col in metadata_dict and col in df.columns:\n",
        "            translated[f\"{col}_DESC\"] = translate_column_values(df, col, metadata_dict)\n",
        "            print(f\"Translated {col}\")\n",
        "        else:\n",
        "            print(f\"Skipped {col} (not found in metadata or dataframe)\")\n",
        "\n",
        "    return translated\n",
        "\n",
        "# Translate several categorical columns\n",
        "columns_to_translate = ['_STATE', 'FMONTH', 'DISPCODE', 'SEX1']\n",
        "translations = batch_translate_columns(bfrss_raw_df, columns_to_translate, bfrss_metadata)\n",
        "\n",
        "# Add translations to dataframe\n",
        "for col_name, translated_series in translations.items():\n",
        "    bfrss_raw_df[col_name] = translated_series\n",
        "\n",
        "# Show sample of multiple translations\n",
        "print(\"\\nSample of translated data:\")\n",
        "original_cols = columns_to_translate[:3]  # Show first 3\n",
        "desc_cols = [f\"{col}_DESC\" for col in original_cols]\n",
        "print(bfrss_raw_df[original_cols + desc_cols].head())"
      ],
      "metadata": {
        "id": "G-WvLDeMPiXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 6: Getting columns by Section Name"
      ],
      "metadata": {
        "id": "KjzzVNlTT_71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple example: Get all column names for 'Calculated Variables' section\n",
        "calculated_columns = [col for col, meta in bfrss_metadata.items()\n",
        "                     if meta.section_name == 'Calculated Variables']\n",
        "\n",
        "print(f\"Columns in 'Calculated Variables' section: {len(calculated_columns)}\")\n",
        "print(f\"\\nColumn names: {calculated_columns}\")"
      ],
      "metadata": {
        "id": "Degwj_IgbGK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjWCW3A2hTPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kelly Scratch\n",
        "\n",
        "- making own copies of data for experimentation: k_df, k_metadata\n"
      ],
      "metadata": {
        "id": "mMTzF2nXbXaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "agXugo3khXu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_df = bfrss_raw_df.copy()\n",
        "k_metadata = bfrss_metadata.copy()\n",
        "\n",
        "# Metadata Tests\n",
        "##\n",
        "\n",
        "k_m_df = pd.DataFrame.from_dict(k_metadata, orient='index')\n",
        "k_m_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "yW4EYaNthYdj",
        "outputId": "f06cbe53-a570-4d97-8403-e04945ed7d20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bfrss_raw_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d0f6ade0a3b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbfrss_raw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbfrss_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Metadata Tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bfrss_raw_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "1iWGgG0Pbaw0"
      }
    }
  ]
}