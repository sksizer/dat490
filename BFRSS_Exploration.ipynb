{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "YMzEMIm7Iuw6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sksizer/dat490/blob/main/BFRSS_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "- check env\n",
        "- set and test paths for data"
      ],
      "metadata": {
        "id": "YMzEMIm7Iuw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython import get_ipython\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def is_colab():\n",
        "    return 'google.colab' in str(get_ipython())\n",
        "\n",
        "if is_colab() and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if is_colab():\n",
        "    BFRSS_DATA_PATH = '/content/drive/MyDrive/DAT490/data/LLCP2023.parquet'\n",
        "    BFRSS_CODEBOOK_PATH = '/content/drive/MyDrive/DAT490/data/codebook_USCODE23_LLCP_021924.HTML'\n",
        "else:\n",
        "    BFRSS_CODEBOOK_PATH = './data/'\n",
        "    BFRSS_DATA_PATH = './data/'\n",
        "\n",
        "if not os.path.exists(BFRSS_DATA_PATH):\n",
        "    raise Exception(f\"Data path ${BFRSS_DATA_PATH} does not exist\")\n",
        "\n",
        "if not os.path.exists(BFRSS_CODEBOOK_PATH):\n",
        "    raise Exception(f\"Codebook path ${BFRSS_CODEBOOK_PATH} does not exist\")\n",
        "logger.info('Environment setup complete')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVJYYPAYIT8C",
        "outputId": "c8affe57-244f-496c-caa9-50b126c00115"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Environment setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data and Metadata\n",
        "- creates starting DF `bfrss_raw_df` from BFRSS data\n",
        "- extract metadata: parses [Codebook](https://github.com/sksizer/dat490/blob/ main/data/codebook_USCODE23_LLCP_021924.HTML) into a dictionary that uses columns as keys:\n",
        "  ```\n",
        "  bfrss_metadata\n",
        "  # to get the metadata for a column:\n",
        "  bfrss_metadata['COLUMN1']\n",
        "\n",
        "  # It also has value to value descriptions such as:\n",
        "  bfrss_metadata['COLUMN1'].value_lookup[1] # will return something like 'Number of times worked out in last week'\n",
        "  ```"
      ],
      "metadata": {
        "id": "7gcIaBDZpH8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eckrUOR1ilCW",
        "outputId": "35c00c59-78f2-4dde-b629-e5cd94997e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 433323 entries, 0 to 433322\n",
            "Columns: 350 entries, _STATE to _DRNKDRV\n",
            "dtypes: float64(345), object(5)\n",
            "memory usage: 1.1+ GB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "bfrss_raw_df = pd.read_parquet(BFRSS_DATA_PATH)\n",
        "bfrss_raw_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "from bs4 import BeautifulSoup, PageElement\n",
        "\n",
        "\n",
        "class ColumnMetadata(BaseModel):\n",
        "    computed: bool\n",
        "    label: str\n",
        "    sas_variable_name: str\n",
        "    section_name: Optional[str] = None\n",
        "    section_number: Optional[int] = None\n",
        "    question_number: Optional[int] = None\n",
        "    column: Optional[str] = None  # Can be a range like \"1-2\" or single number\n",
        "    type_of_variable: Optional[str] = None  # \"Num\" or \"Char\"\n",
        "    question_prologue: Optional[str] = None\n",
        "    question: Optional[str] = None\n",
        "    value_lookup: dict[None | int, str] # This is a dictionary that returns the textual\n",
        "\n",
        "\n",
        "def get_value_lookup(table:PageElement) -> Dict[None | int, str]:\n",
        "    \"\"\"\n",
        "    Given one of the branch table objects, we can extract out in a fairly\n",
        "    simple manner all the possible values for the target column\n",
        "\n",
        "    Simplified table structure example:\n",
        "    <table>\n",
        "    <tbody>\n",
        "    <tr>\n",
        "    <td>value</td> (which might be a single int value, blank or could be a range\n",
        "    <td>Value description\n",
        "    </tr>\n",
        "    </tbody>\n",
        "    </table>\n",
        "\n",
        "    :param table:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    value_dict : Dict[None | int, str] = {} # Stores the value to value description\n",
        "\n",
        "    for tr in table.find('tbody').find_all('tr'):\n",
        "        cells = tr.find_all('td')\n",
        "        if len(cells) < 2:\n",
        "            continue\n",
        "\n",
        "        value_text = cells[0].text.strip()\n",
        "        description = cells[1].text.strip()\n",
        "\n",
        "        # Check if the value is actually a range such as \"1 - 30\" or \"1-30\"\n",
        "        range_match = re.match(r'^(\\d+)\\s*[-â€“]\\s*(\\d+)$', value_text)\n",
        "        if range_match:\n",
        "            start = int(range_match.group(1))\n",
        "            end = int(range_match.group(2))\n",
        "            # Add each value in the range\n",
        "            # This is kind of ugly because we are creating some value lookups\n",
        "            # that have thousands of values...a function would be better but I\n",
        "            # was trying to keep the metadata 'pure' data\n",
        "            for i in range(start, end + 1):\n",
        "                value_dict[i] = description\n",
        "        else:\n",
        "            # Try to parse as single integer\n",
        "            try:\n",
        "                value = int(value_text)\n",
        "                value_dict[value] = description\n",
        "            except:\n",
        "                # If not a number, store as None\n",
        "                value_dict[None] = description\n",
        "\n",
        "    return value_dict\n",
        "\n",
        "def parse_codebook_html(html_path: Path) -> Dict[str, ColumnMetadata]:\n",
        "    \"\"\"\n",
        "    Parse the BRFSS codebook HTML file and extract column metadata.\n",
        "\n",
        "    Args:\n",
        "        html_path: Path to the HTML codebook file\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping SAS variable names to ColumnMetadata objects\n",
        "    \"\"\"\n",
        "    with open(html_path, 'r', encoding='windows-1252') as f:\n",
        "        html_content = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Find all div elements with class \"branch\"\n",
        "    branches = soup.find_all('div', class_='branch')\n",
        "\n",
        "    # The first one is the Codebook header table which we don't want\n",
        "    branches = branches[1:]\n",
        "\n",
        "    metadata_dict = {}\n",
        "\n",
        "    for branch in branches:\n",
        "        # Find the table with summary=\"Procedure Report: Report\"\n",
        "        table = branch.find('table', attrs={'summary': 'Procedure Report: Report'})\n",
        "        if not table:\n",
        "            continue\n",
        "\n",
        "        # Find the first td in the thead > tr\n",
        "        thead = table.find('thead')\n",
        "        if not thead:\n",
        "            continue\n",
        "\n",
        "        first_tr = thead.find('tr')\n",
        "        if not first_tr:\n",
        "            continue\n",
        "\n",
        "        # Find td with metadata content - may not have all classes\n",
        "        metadata_cell = None\n",
        "        for td in first_tr.find_all('td'):\n",
        "            text = td.get_text()\n",
        "            if text:\n",
        "                # Clean text before checking\n",
        "                text_clean = text.replace('\\xa0', ' ')\n",
        "                if 'Label:' in text_clean and 'SAS Variable Name:' in text_clean:\n",
        "                    metadata_cell = td\n",
        "                    break\n",
        "\n",
        "        if not metadata_cell:\n",
        "            continue\n",
        "\n",
        "        cell_text = metadata_cell.get_text()\n",
        "\n",
        "        # Check if this cell contains column metadata by looking for key fields\n",
        "        try:\n",
        "            # Extract fields using regex - handle non-breaking spaces\n",
        "            cell_text = cell_text.replace('\\xa0', ' ')  # Replace non-breaking spaces\n",
        "\n",
        "            label_match = re.search(r'Label:\\s*(.+?)(?=Section\\s*Name:|Core\\s*Section\\s*Number:|$)', cell_text, re.DOTALL)\n",
        "            section_name_match = re.search(r'Section\\s*Name:\\s*(.+?)(?=Core\\s*Section\\s*Number:|Section\\s*Number:|$)', cell_text, re.DOTALL)\n",
        "            # Handle both \"Core Section Number\" and \"Section Number\"\n",
        "            section_number_match = re.search(r'(?:Core\\s*)?Section\\s*Number:\\s*(\\d+)', cell_text)\n",
        "            question_number_match = re.search(r'Question\\s*Number:\\s*(\\d+)', cell_text)\n",
        "            column_match = re.search(r'Column:\\s*(.+?)(?=Type\\s*of\\s*Variable:|$)', cell_text, re.DOTALL)\n",
        "            type_match = re.search(r'Type\\s*of\\s*Variable:\\s*(.+?)(?=SAS\\s*Variable\\s*Name:|$)', cell_text, re.DOTALL)\n",
        "            sas_name_match = re.search(r'SAS\\s*Variable\\s*Name:\\s*(.+?)(?=Question\\s*Prologue:|Question:|$)', cell_text, re.DOTALL)\n",
        "            prologue_match = re.search(r'Question\\s*Prologue:\\s*(.+?)(?=Question:|$)', cell_text, re.DOTALL)\n",
        "            question_match = re.search(r'Question:\\s*(.+?)$', cell_text, re.DOTALL)\n",
        "\n",
        "            # Only require label and SAS variable name\n",
        "            if label_match and sas_name_match:\n",
        "\n",
        "                # Clean up the extracted values\n",
        "                label = label_match.group(1).strip()\n",
        "                sas_variable_name = sas_name_match.group(1).strip()\n",
        "\n",
        "                # Extract optional fields\n",
        "                section_name = section_name_match.group(1).strip() if section_name_match else None\n",
        "                section_number = int(section_number_match.group(1)) if section_number_match else None\n",
        "                question_number = int(question_number_match.group(1)) if question_number_match else None\n",
        "                column = column_match.group(1).strip() if column_match else None\n",
        "                type_of_variable = type_match.group(1).strip() if type_match else None\n",
        "                question_prologue = prologue_match.group(1).strip() if prologue_match else None\n",
        "                question = question_match.group(1).strip() if question_match else None\n",
        "\n",
        "                # Remove any extra whitespace or newlines\n",
        "                if question_prologue and not question_prologue:\n",
        "                    question_prologue = None\n",
        "\n",
        "                # Create ColumnMetadata object\n",
        "                metadata = ColumnMetadata(\n",
        "                    label=label,\n",
        "                    sas_variable_name=sas_variable_name,\n",
        "                    section_name=section_name,\n",
        "                    section_number=section_number,\n",
        "                    question_number=question_number,\n",
        "                    column=column,\n",
        "                    type_of_variable=type_of_variable,\n",
        "                    question_prologue=question_prologue,\n",
        "                    question=question,\n",
        "                    value_lookup=get_value_lookup(table),\n",
        "                    computed= True if section_name == 'Calculated Variables' or section_name == 'Calculated Race Variables' else False\n",
        "                )\n",
        "\n",
        "                metadata_dict[sas_variable_name] = metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            # Skip cells that don't parse correctly but show problems\n",
        "            print(e)\n",
        "\n",
        "    return metadata_dict\n",
        "\n",
        "\n",
        "bfrss_metadata = parse_codebook_html(BFRSS_CODEBOOK_PATH)"
      ],
      "metadata": {
        "id": "xYWEooJMAwr6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of columns parsed\n",
        "print(f\"Parsed {len(bfrss_metadata)} column definitions from the codebook\")\n",
        "\n",
        "# Show a sample of the metadata\n",
        "sample_keys = list(bfrss_metadata.keys())[:5]\n",
        "for key in sample_keys:\n",
        "    metadata = bfrss_metadata[key]\n",
        "    print(f\"\\n{key}:\")\n",
        "    print(f\"  Label: {metadata.label}\")\n",
        "    print(f\"  Question: {metadata.question}\")\n",
        "    print(f\"  Column: {metadata.column}\")\n",
        "    print(f\"  Type: {metadata.type_of_variable}\")\n",
        "    print(f\"  Computed: {metadata.computed}\")\n",
        "    print(f\"  Section Name: {metadata.section_name}\")\n",
        "    print(f\"  Section Number: {metadata.section_number}\")\n",
        "    print(f\"  Question Number: {metadata.question_number}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTKxZUFcNlao",
        "outputId": "f066fc79-ef4b-4bcd-a6d9-df6dfa95101c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed 344 column definitions from the codebook\n",
            "\n",
            "_STATE:\n",
            "  Label: State FIPS Code\n",
            "  Question: State FIPS Code\n",
            "  Column: 1-2\n",
            "  Type: Num\n",
            "  Computed: False\n",
            "  Section Name: Record Identification\n",
            "  Section Number: 0\n",
            "  Question Number: 1\n",
            "\n",
            "FMONTH:\n",
            "  Label: File Month\n",
            "  Question: File Month\n",
            "  Column: 17-18\n",
            "  Type: Num\n",
            "  Computed: False\n",
            "  Section Name: Record Identification\n",
            "  Section Number: 0\n",
            "  Question Number: 8\n",
            "\n",
            "IDATE:\n",
            "  Label: Interview Date\n",
            "  Question: Interview Date\n",
            "  Column: 19-26\n",
            "  Type: Char\n",
            "  Computed: False\n",
            "  Section Name: Record Identification\n",
            "  Section Number: 0\n",
            "  Question Number: 9\n",
            "\n",
            "IMONTH:\n",
            "  Label: Interview Month\n",
            "  Question: Interview Month\n",
            "  Column: 19-20\n",
            "  Type: Char\n",
            "  Computed: False\n",
            "  Section Name: Record Identification\n",
            "  Section Number: 0\n",
            "  Question Number: 10\n",
            "\n",
            "IDAY:\n",
            "  Label: Interview Day\n",
            "  Question: Interview Day\n",
            "  Column: 21-22\n",
            "  Type: Char\n",
            "  Computed: False\n",
            "  Section Name: Record Identification\n",
            "  Section Number: 0\n",
            "  Question Number: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata Documentation\n",
        "Notes and examples of the metadata extraction:\n",
        "\n"
      ],
      "metadata": {
        "id": "XgwFJt3YNBjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total columns in dataframe: {len(bfrss_raw_df.columns)}\")\n",
        "print(f\"Total metadata parsed: {len(bfrss_metadata)}\")\n",
        "print(f\"Coverage: {len(bfrss_metadata) / len(bfrss_raw_df.columns) * 100:.1f}%\")\n",
        "\n",
        "# Check which columns don't have metadata\n",
        "missing_metadata = [col for col in bfrss_raw_df.columns if col not in bfrss_metadata]\n",
        "print(f\"\\nColumns without metadata: {len(missing_metadata)}\")\n",
        "if missing_metadata:\n",
        "    print(\"First 10 missing:\", missing_metadata[:10])\n",
        "print(\"Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGcHPEctN3yb",
        "outputId": "0ce94886-11cb-4e17-d6b8-45a5c20551b7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total columns in dataframe: 350\n",
            "Total metadata parsed: 344\n",
            "Coverage: 98.3%\n",
            "\n",
            "Columns without metadata: 7\n",
            "First 10 missing: ['LNDSXBRT', 'CELSXBRT', 'BIRTHSEX', 'TRNSGNDR', 'USEMRJN4', 'RCSGEND1', 'RCSXBRTH']\n",
            "Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Friendly Mapping Feature\n",
        "(note I generated the following docs and examples with ChatGPT, but I've vetted all of it)\n",
        "\n",
        "The metadata parser includes a powerful \"friendly mapping\" feature that translates numeric codes in the dataset to their human-readable descriptions. This is particularly useful for categorical variables where numeric codes represent specific responses.\n",
        "\n",
        "### How It Works\n",
        "\n",
        "Each `ColumnMetadata` object contains a `value_lookup` dictionary that maps numeric values (or None) to their text descriptions. This mapping is automatically extracted from the codebook HTML file during parsing.\n",
        "\n",
        "#### Key Components:\n",
        "\n",
        "1. **`value_lookup` dictionary**: Found in each `ColumnMetadata` object\n",
        "   - Keys: Numeric codes (int) or None\n",
        "   - Values: Human-readable descriptions (str)\n",
        "\n",
        "2. **Automatic extraction**: The `get_value_lookup()` function in `parser.py` extracts these mappings from HTML tables in the codebook"
      ],
      "metadata": {
        "id": "CUSQ1RmqOssx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Understanding what values mean for a specific column"
      ],
      "metadata": {
        "id": "gODrkHvrTg-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Understanding what values mean for a specific column\n",
        "# Let's look at the _STATE column which has distinct state codes\n",
        "\n",
        "state_metadata = bfrss_metadata['_STATE']\n",
        "print(f\"Column: {state_metadata.sas_variable_name}\")\n",
        "print(f\"Label: {state_metadata.label}\")\n",
        "print(f\"Question: {state_metadata.question}\")\n",
        "print(f\"\\nSample of value mappings (first 10):\")\n",
        "# Show first 10 state mappings\n",
        "for i, (value, description) in enumerate(state_metadata.value_lookup.items()):\n",
        "    if i < 10:\n",
        "        print(f\"  {value}: {description}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rJpt2FIOttO",
        "outputId": "1ecac73f-725e-4acb-b8c9-0dd2aa55720e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: _STATE\n",
            "Label: State FIPS Code\n",
            "Question: State FIPS Code\n",
            "\n",
            "Sample of value mappings (first 10):\n",
            "  1: Alabama\n",
            "  2: Alaska\n",
            "  4: Arizona\n",
            "  5: Arkansas\n",
            "  6: California\n",
            "  8: Colorado\n",
            "  9: Connecticut\n",
            "  10: Delaware\n",
            "  11: District of Columbia\n",
            "  12: Florida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V21re5obTSh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Translating values in your data"
      ],
      "metadata": {
        "id": "GNl8M6BgTppS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Translating values in your data\n",
        "# Let's translate some actual STATE values from the dataframe\n",
        "\n",
        "# Get a sample of state values\n",
        "sample_values = bfrss_raw_df['_STATE'].value_counts().head(10)\n",
        "print(\"Top 10 states by number of respondents:\\n\")\n",
        "\n",
        "for value, count in sample_values.items():\n",
        "    # Get the description from value_lookup\n",
        "    description = state_metadata.value_lookup.get(int(value) if not pd.isna(value) else None, \"Unknown\")\n",
        "    print(f\"Code {int(value)}: {description} (Count: {count:,})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxFI_rkHPEge",
        "outputId": "1dd1be0b-ef13-4c10-ffe6-58c1f65c21e0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 states by number of respondents:\n",
            "\n",
            "Code 53: Washington (Count: 26,444)\n",
            "Code 36: New York (Count: 17,349)\n",
            "Code 24: Maryland (Count: 17,255)\n",
            "Code 27: Minnesota (Count: 16,170)\n",
            "Code 39: Ohio (Count: 13,384)\n",
            "Code 12: Florida (Count: 13,255)\n",
            "Code 31: Nebraska (Count: 12,886)\n",
            "Code 55: Wisconsin (Count: 12,819)\n",
            "Code 23: Maine (Count: 12,255)\n",
            "Code 4: Arizona (Count: 12,036)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Creating a mapping function for easy translation"
      ],
      "metadata": {
        "id": "CZ2PT79QTvWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Creating a mapping function for easy translation\n",
        "def translate_column_values(df, column_name, metadata_dict):\n",
        "    \"\"\"\n",
        "    Translate numeric codes to descriptions for a specific column.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe containing the data\n",
        "        column_name: Name of the column to translate\n",
        "        metadata_dict: Dictionary of column metadata\n",
        "\n",
        "    Returns:\n",
        "        Pandas Series with translated values\n",
        "    \"\"\"\n",
        "    if column_name not in metadata_dict:\n",
        "        print(f\"No metadata found for column: {column_name}\")\n",
        "        return df[column_name]\n",
        "\n",
        "    metadata = metadata_dict[column_name]\n",
        "\n",
        "    # Create translation function\n",
        "    def translate(value):\n",
        "        if pd.isna(value):\n",
        "            return \"Missing\"\n",
        "        return metadata.value_lookup.get(int(value), f\"Unknown code: {value}\")\n",
        "\n",
        "    return df[column_name].apply(translate)\n",
        "\n",
        "# Example usage - translate STATE codes\n",
        "bfrss_raw_df['STATE_NAME'] = translate_column_values(bfrss_raw_df, '_STATE', bfrss_metadata)\n",
        "\n",
        "# Show sample\n",
        "print(\"Sample of translated state values:\")\n",
        "print(bfrss_raw_df[['_STATE', 'STATE_NAME']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g1Yxo9qO7Jt",
        "outputId": "17b4b34c-332e-43bb-abe8-d863d26eb964"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of translated state values:\n",
            "   _STATE STATE_NAME\n",
            "0     1.0    Alabama\n",
            "1     1.0    Alabama\n",
            "2     1.0    Alabama\n",
            "3     1.0    Alabama\n",
            "4     1.0    Alabama\n",
            "5     1.0    Alabama\n",
            "6     1.0    Alabama\n",
            "7     1.0    Alabama\n",
            "8     1.0    Alabama\n",
            "9     1.0    Alabama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 4: Working with columns that have ranges"
      ],
      "metadata": {
        "id": "AAj4ILpoTzGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: Working with columns that have ranges\n",
        "# Now let's test with POORHLTH which has a range value \"1 - 30\"\n",
        "poorhlth_metadata = bfrss_metadata['POORHLTH']\n",
        "print(f\"Column: {poorhlth_metadata.sas_variable_name}\")\n",
        "print(f\"Label: {poorhlth_metadata.label}\")\n",
        "\n",
        "# Check if the range was properly expanded\n",
        "print(f\"\\nTotal value mappings: {len(poorhlth_metadata.value_lookup)}\")\n",
        "print(\"\\nSample mappings:\")\n",
        "# Show some specific values to verify range expansion\n",
        "for value in [1, 15, 30, 77, 88, 99]:\n",
        "    if value in poorhlth_metadata.value_lookup:\n",
        "        print(f\"  {value}: {poorhlth_metadata.value_lookup[value]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3GMA7-BPWDz",
        "outputId": "01dc8c3f-28a1-4983-9d69-17b637c54e54"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: POORHLTH\n",
            "Label: Poor Physical or Mental Health\n",
            "\n",
            "Total value mappings: 34\n",
            "\n",
            "Sample mappings:\n",
            "  1: Number of daysNotes: _ _ Number of days\n",
            "  15: Number of daysNotes: _ _ Number of days\n",
            "  30: Number of daysNotes: _ _ Number of days\n",
            "  77: Don't know/Not sure\n",
            "  88: None\n",
            "  99: Refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 5: Batch translation of multiple columns"
      ],
      "metadata": {
        "id": "pEdPwWOXT9sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5: Batch translation of multiple columns\n",
        "# This example shows how to efficiently translate multiple columns at once\n",
        "\n",
        "def batch_translate_columns(df, column_list, metadata_dict):\n",
        "    \"\"\"\n",
        "    Translate multiple columns from numeric codes to descriptions.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe containing the data\n",
        "        column_list: List of column names to translate\n",
        "        metadata_dict: Dictionary of column metadata\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of translated series\n",
        "    \"\"\"\n",
        "    translated = {}\n",
        "\n",
        "    for col in column_list:\n",
        "        if col in metadata_dict and col in df.columns:\n",
        "            translated[f\"{col}_DESC\"] = translate_column_values(df, col, metadata_dict)\n",
        "            print(f\"Translated {col}\")\n",
        "        else:\n",
        "            print(f\"Skipped {col} (not found in metadata or dataframe)\")\n",
        "\n",
        "    return translated\n",
        "\n",
        "# Translate several categorical columns\n",
        "columns_to_translate = ['_STATE', 'FMONTH', 'DISPCODE', 'SEX1']\n",
        "translations = batch_translate_columns(bfrss_raw_df, columns_to_translate, bfrss_metadata)\n",
        "\n",
        "# Add translations to dataframe\n",
        "for col_name, translated_series in translations.items():\n",
        "    bfrss_raw_df[col_name] = translated_series\n",
        "\n",
        "# Show sample of multiple translations\n",
        "print(\"\\nSample of translated data:\")\n",
        "original_cols = columns_to_translate[:3]  # Show first 3\n",
        "desc_cols = [f\"{col}_DESC\" for col in original_cols]\n",
        "print(bfrss_raw_df[original_cols + desc_cols].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-WvLDeMPiXj",
        "outputId": "4830133a-7627-4415-8753-7d8a488150eb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated _STATE\n",
            "Translated FMONTH\n",
            "Translated DISPCODE\n",
            "Skipped SEX1 (not found in metadata or dataframe)\n",
            "\n",
            "Sample of translated data:\n",
            "   _STATE  FMONTH  DISPCODE _STATE_DESC FMONTH_DESC        DISPCODE_DESC\n",
            "0     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
            "1     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
            "2     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
            "3     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
            "4     1.0     1.0    1100.0     Alabama     January  Completed Interview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binning by Section Name"
      ],
      "metadata": {
        "id": "KjzzVNlTT_71"
      }
    }
  ]
}