{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sksizer/dat490/blob/main/BFRSS_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMzEMIm7Iuw6"
   },
   "source": [
    "# Environment Setup\n",
    "- check env\n",
    "- set and test paths for data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:06:45.706629Z",
     "start_time": "2025-06-06T23:06:45.699103Z"
    }
   },
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "import urllib.request\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in str(get_ipython())\n",
    "\n",
    "def download_if_needed(url: str, filename: str) -> str:\n",
    "    \"\"\"Download a file if it doesn't already exist.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Using cached file: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Set up file paths\n",
    "if is_colab():\n",
    "    BFRSS_DATA_PATH = download_if_needed(\n",
    "        \"https://singular-eclair-6a5a16.netlify.app/LLCP2023.parquet\",\n",
    "        \"LLCP2023.parquet\"\n",
    "    )\n",
    "    BFRSS_CODEBOOK_PATH = download_if_needed(\n",
    "        \"https://singular-eclair-6a5a16.netlify.app/html/codebook_USCODE23_LLCP_021924.HTML\",\n",
    "        \"codebook_USCODE23_LLCP_021924.HTML\"\n",
    "    )\n",
    "else:\n",
    "    BFRSS_DATA_PATH = './data/LLCP2023.parquet'\n",
    "    BFRSS_CODEBOOK_PATH = './data/codebook_USCODE23_LLCP_021924.HTML'\n",
    "\n",
    "# Check file existence\n",
    "if not os.path.exists(BFRSS_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Data path {BFRSS_DATA_PATH} does not exist\")\n",
    "\n",
    "if not os.path.exists(BFRSS_CODEBOOK_PATH):\n",
    "    raise FileNotFoundError(f\"Codebook path {BFRSS_CODEBOOK_PATH} does not exist\")\n",
    "\n",
    "logger.info('Environment setup complete')\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gcIaBDZpH8O"
   },
   "source": [
    "# Load Data and Metadata\n",
    "- creates starting DF `bfrss_raw_df` from BFRSS data\n",
    "- extract metadata: parses [Codebook](https://github.com/sksizer/dat490/blob/main/data/codebook_USCODE23_LLCP_021924.HTML) into a dictionary that uses columns as keys:\n",
    "  ```\n",
    "  bfrss_metadata\n",
    "  # to get the metadata for a column:\n",
    "  bfrss_metadata['COLUMN1']\n",
    "\n",
    "  # It also has value to value descriptions such as:\n",
    "  bfrss_metadata['COLUMN1'].value_lookup[1] # will return something like 'Number of times worked out in last week'\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eckrUOR1ilCW",
    "ExecuteTime": {
     "end_time": "2025-06-06T23:06:47.772025Z",
     "start_time": "2025-06-06T23:06:45.737542Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "bfrss_raw_df = pd.read_parquet(BFRSS_DATA_PATH)\n",
    "bfrss_raw_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 433323 entries, 0 to 433322\n",
      "Columns: 350 entries, _STATE to _DRNKDRV\n",
      "dtypes: float64(345), object(5)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:06:47.835530Z",
     "start_time": "2025-06-06T23:06:47.814368Z"
    }
   },
   "cell_type": "code",
   "source": "bfrss_raw_df.loc[:,'_AGEG5YR'].describe()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    433323.000000\n",
       "mean          7.836318\n",
       "std           3.694292\n",
       "min           1.000000\n",
       "25%           5.000000\n",
       "50%           8.000000\n",
       "75%          11.000000\n",
       "max          14.000000\n",
       "Name: _AGEG5YR, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:06:48.020700Z",
     "start_time": "2025-06-06T23:06:47.896112Z"
    }
   },
   "source": "import re\nfrom pathlib import Path\nfrom typing import Optional, Dict, List, Any, Union\n\nimport pandas as pd\nfrom bs4 import PageElement, BeautifulSoup\n\nfrom pydantic import BaseModel, Field\n\n\nclass ValueDef(BaseModel):\n    \"\"\"Base model for representing value definitions in BRFSS survey data.\"\"\"\n    description: str\n    missing: bool = Field(default=False)\n\n\nclass ValueRange(ValueDef):\n    \"\"\"Model for value definitions that have a numeric range (single value or range of values).\"\"\"\n    start: int\n    end: int\n    count: int  # How many values fall in this range\n\n\nclass ColumnStatistics(BaseModel):\n    \"\"\"Base model for statistical information about a column.\"\"\"\n    count: int                          # Number of non-null values\n    null_count: int                     # Number of null values\n    unique_count: Optional[int] = None  # Number of unique values\n\n\nclass NumericStatistics(ColumnStatistics):\n    \"\"\"Statistical information for numeric columns.\"\"\"\n    mean: Optional[float] = None        # Mean value\n    std: Optional[float] = None         # Standard deviation\n    min: Optional[float] = None         # Minimum value\n    q25: Optional[float] = None         # 25th percentile\n    median: Optional[float] = None      # Median value (50th percentile)\n    q75: Optional[float] = None         # 75th percentile\n    max: Optional[float] = None         # Maximum value\n\n\nclass CategoricalStatistics(ColumnStatistics):\n    \"\"\"Statistical information for categorical columns.\"\"\"\n    value_counts: Dict[str, int]        # Count of each unique value\n    top_values: List[Dict[str, Any]]    # List of most common values with counts\n\n\nclass ColumnMetadata(BaseModel):\n    \"\"\"\n    Model representing metadata for a single column in the BRFSS dataset.\n    Contains information parsed from the codebook including variable details,\n    associated question text, and possible values.\n    \"\"\"\n    computed: bool                      # Whether this is a calculated/derived variable\n    label: str                          # Human-readable label for the variable\n    sas_variable_name: str              # Original SAS variable name from dataset\n    section_name: Optional[str] = None  # Name of the survey section\n    section_number: Optional[int] = None # Core section number\n    module_number: Optional[int] = None # Module number for optional modules\n    question_number: Optional[int] = None # Question number within section\n    column: Optional[str] = None        # Column position in dataset (can be range like \"1-2\")\n    type_of_variable: Optional[str] = None # \"Num\" or \"Char\"\n    question_prologue: Optional[str] = None # Text before the actual question\n    question: Optional[str] = None      # The actual question text from survey\n    value_lookup: list[ValueDef | ValueRange]        # Possible values for this variable\n    html_name: str                      # HTML anchor name for linking to codebook\n    statistics: Optional[Union[NumericStatistics, CategoricalStatistics]] = None  # Statistical information\n\n\ndef get_value_def(tr:PageElement, df: Optional[pd.DataFrame] = None, column_name: Optional[str] = None) -> ValueDef | ValueRange:\n    \"\"\"\n    Extract value definition from a table row in the codebook.\n\n    Parses a table row containing value codes and their descriptions. Handles both\n    single values and ranges (e.g., \"1-30\"). If DataFrame and column name are provided,\n    calculates the count of values in the range.\n\n    Args:\n        tr: BeautifulSoup PageElement representing a table row with value information\n        df: Optional DataFrame containing the data\n        column_name: Optional column name to calculate counts for\n\n    Returns:\n        Either a ValueDef (for non-numeric or unparseable values) or\n        ValueRange (for single numbers or numeric ranges)\n    \"\"\"\n    cells = tr.find_all('td')\n\n    value_text = cells[0].text.strip()\n    description = cells[1].text.strip()\n\n    # Check if the value is actually a range such as \"1 - 30\" or \"1-30\"\n    range_match = re.match(r'^(\\d+)\\s*[-â€“]\\s*(\\d+)$', value_text)\n    if range_match:\n        start = int(range_match.group(1))\n        end = int(range_match.group(2))\n\n        # Calculate count if DataFrame and column are provided\n        count = 0\n        if df is not None and column_name is not None and column_name in df.columns:\n            try:\n                series = df[column_name]\n                # Count values in the range (inclusive)\n                count = int(series.between(start, end, inclusive='both').sum())\n            except Exception as e:\n                print(f\"Error calculating count for range {start}-{end} in column {column_name}: {e}\")\n                count = 0\n\n        return ValueRange(\n            start=start,\n            end=end,\n            description=description,\n            count=count\n        )\n    else:\n        # Try to parse as single integer\n        try:\n            value = int(value_text)\n\n            # Calculate count if DataFrame and column are provided\n            count = 0\n            if df is not None and column_name is not None and column_name in df.columns:\n                try:\n                    series = df[column_name]\n                    # Count occurrences of this specific value\n                    count = int((series == value).sum())\n                except Exception as e:\n                    print(f\"Error calculating count for value {value} in column {column_name}: {e}\")\n                    count = 0\n\n            return ValueRange(\n                start=value,\n                end=value,\n                description=description,\n                count=count\n            )\n        except:\n            return ValueDef(\n                description=description\n            )\n\n\ndef get_value_lookup(table:PageElement, df: Optional[pd.DataFrame] = None, column_name: Optional[str] = None) -> list[ValueDef]:\n    \"\"\"\n    Extract all possible values for a column from a codebook table.\n\n    Given a table from the codebook HTML, extracts all value definitions\n    (codes and their descriptions) from the rows. If DataFrame and column name\n    are provided, calculates counts for ValueRange objects.\n\n    Args:\n        table: BeautifulSoup PageElement representing a table containing value codes\n              and descriptions\n        df: Optional DataFrame containing the data\n        column_name: Optional column name to calculate counts for\n\n    Returns:\n        List of ValueDef/ValueRange objects containing all possible values\n        for the column\n\n    Example table structure:\n    <table>\n    <tbody>\n    <tr>\n        <td>value</td> <!-- single int value, blank, or range like \"1-30\" -->\n        <td>Value description</td>\n    </tr>\n    </tbody>\n    </table>\n    \"\"\"\n    value_ranges : list[ValueDef] = []\n\n    for tr in table.find('tbody').find_all('tr'):\n        value_ranges.append(get_value_def(tr, df, column_name))\n\n    return value_ranges\n\n\ndef parse_codebook_html(html_path: Path, df: Optional[pd.DataFrame] = None) -> Dict[str, ColumnMetadata]:\n    \"\"\"\n    Parse the BRFSS codebook HTML file and extract column metadata.\n\n    Args:\n        html_path: Path to the HTML codebook file\n        df: Optional DataFrame containing BRFSS data for calculating statistics\n\n    Returns:\n        Dictionary mapping SAS variable names to ColumnMetadata objects\n    \"\"\"\n    with open(html_path, 'r', encoding='windows-1252') as f:\n        html_content = f.read()\n\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    # Find all div elements with class \"branch\"\n    branches = soup.find_all('div', class_='branch')\n\n    # The first one is the Codebook header table which we don't want\n    branches = branches[1:]\n\n    metadata_dict = {}\n\n    for branch in branches:\n        html_name = branch.find('a')['name']\n        print('html_name' + html_name)\n        # Find the table with summary=\"Procedure Report: Report\"\n        table = branch.find('table', attrs={'summary': 'Procedure Report: Report'})\n        if not table:\n            continue\n\n        # Find the first td in the thead > tr\n        thead = table.find('thead')\n        if not thead:\n            continue\n\n        first_tr = thead.find('tr')\n        if not first_tr:\n            continue\n\n        # Find td with metadata content - may not have all classes\n        metadata_cell = None\n        for td in first_tr.find_all('td'):\n            text = td.get_text()\n            if text:\n                # Clean text before checking\n                text_clean = text.replace('\\xa0', ' ')\n                if 'Label:' in text_clean and 'SAS Variable Name:' in text_clean:\n                    metadata_cell = td\n                    break\n\n        if not metadata_cell:\n            continue\n\n        cell_text = metadata_cell.get_text()\n\n        # Check if this cell contains column metadata by looking for key fields\n        try:\n            # Extract fields using regex - handle non-breaking spaces\n            cell_text = cell_text.replace('\\xa0', ' ')  # Replace non-breaking spaces\n\n            label_match = re.search(r'Label:\\s*(.+?)(?=Section\\s*Name:|Core\\s*Section\\s*Number:|Module\\s*Number:|$)', cell_text, re.DOTALL)\n            section_name_match = re.search(r'Section\\s*Name:\\s*(.+?)(?=Core\\s*Section\\s*Number:|Section\\s*Number:|Module\\s*Number:|Question\\s*Number:|$)', cell_text, re.DOTALL)\n            # Handle both \"Core Section Number\" and \"Section Number\"\n            section_number_match = re.search(r'(?:Core\\s*)?Section\\s*Number:\\s*(\\d+)', cell_text)\n            # Handle \"Module Number\"\n            module_number_match = re.search(r'Module\\s*Number:\\s*(\\d+)', cell_text)\n            question_number_match = re.search(r'Question\\s*Number:\\s*(\\d+)', cell_text)\n            column_match = re.search(r'Column:\\s*(.+?)(?=Type\\s*of\\s*Variable:|$)', cell_text, re.DOTALL)\n            type_match = re.search(r'Type\\s*of\\s*Variable:\\s*(.+?)(?=SAS\\s*Variable\\s*Name:|$)', cell_text, re.DOTALL)\n            sas_name_match = re.search(r'SAS\\s*Variable\\s*Name:\\s*(.+?)(?=Question\\s*Prologue:|Question:|$)', cell_text, re.DOTALL)\n            prologue_match = re.search(r'Question\\s*Prologue:\\s*(.+?)(?=Question:|$)', cell_text, re.DOTALL)\n            question_match = re.search(r'Question:\\s*(.+?)$', cell_text, re.DOTALL)\n\n            # Only require label and SAS variable name\n            if label_match and sas_name_match:\n\n                # Clean up the extracted values\n                label = label_match.group(1).strip()\n                sas_variable_name = sas_name_match.group(1).strip()\n\n                # Extract optional fields\n                section_name = section_name_match.group(1).strip() if section_name_match else None\n                section_number = int(section_number_match.group(1)) if section_number_match else None\n                module_number = int(module_number_match.group(1)) if module_number_match else None\n                question_number = int(question_number_match.group(1)) if question_number_match else None\n                column = column_match.group(1).strip() if column_match else None\n                type_of_variable = type_match.group(1).strip() if type_match else None\n                question_prologue = prologue_match.group(1).strip() if prologue_match else None\n                question = question_match.group(1).strip() if question_match else None\n\n                # Remove any extra whitespace or newlines\n                if question_prologue and not question_prologue:\n                    question_prologue = None\n\n                # Calculate statistics if DataFrame is provided and column exists\n                statistics = None\n                if df is not None and sas_variable_name in df.columns:\n                    series = df[sas_variable_name]\n\n                    # Common statistics for all columns\n                    count = series.count()\n                    null_count = series.isna().sum()\n                    unique_count = series.nunique()\n\n                    # Determine if column should be treated as numeric or categorical\n                    is_numeric = False\n                    if type_of_variable == \"Num\" and pd.api.types.is_numeric_dtype(series):\n                        try:\n                            # Calculate numeric statistics\n                            desc = series.describe()\n\n                            # Create numeric statistics\n                            statistics = NumericStatistics(\n                                count=count,\n                                null_count=null_count,\n                                unique_count=unique_count,\n                                mean=float(desc['mean']) if not pd.isna(desc['mean']) else None,\n                                std=float(desc['std']) if not pd.isna(desc['std']) else None,\n                                min=float(desc['min']) if not pd.isna(desc['min']) else None,\n                                q25=float(desc['25%']) if not pd.isna(desc['25%']) else None,\n                                median=float(desc['50%']) if not pd.isna(desc['50%']) else None,\n                                q75=float(desc['75%']) if not pd.isna(desc['75%']) else None,\n                                max=float(desc['max']) if not pd.isna(desc['max']) else None\n                            )\n                            is_numeric = True\n                        except Exception as e:\n                            print(f\"Error calculating numeric stats for {sas_variable_name}: {e}\")\n                            is_numeric = False\n\n                    # If not numeric or numeric calculation failed, treat as categorical\n                    if not is_numeric:\n                        try:\n                            # Get value counts (limited to top 20 for brevity)\n                            value_counts = series.value_counts().head(20).to_dict()\n\n                            # Convert all keys to strings for JSON compatibility\n                            value_counts_str = {str(k): int(v) for k, v in value_counts.items()}\n\n                            # Create list of top values with counts and descriptions\n                            top_values = []\n                            for value, count in value_counts.items():\n                                # Try to get description from value_lookup\n                                description = None\n                                value_lookup_list = get_value_lookup(table, df, sas_variable_name)\n                                if isinstance(value, (int, float)) and not pd.isna(value):\n                                    value_int = int(value) if hasattr(value, 'is_integer') and value.is_integer() else int(value) if isinstance(value, int) else None\n                                    # Search through ValueRange objects to find a match\n                                    for val_def in value_lookup_list:\n                                        if isinstance(val_def, ValueRange) and value_int is not None and val_def.start <= value_int <= val_def.end:\n                                            description = val_def.description\n                                            break\n\n                                top_values.append({\n                                    \"value\": str(value),\n                                    \"count\": int(count),\n                                    \"description\": description if description else \"Unknown\"\n                                })\n\n                            # Create categorical statistics\n                            statistics = CategoricalStatistics(\n                                count=count,\n                                null_count=null_count,\n                                unique_count=unique_count,\n                                value_counts=value_counts_str,\n                                top_values=top_values\n                            )\n                        except Exception as e:\n                            print(f\"Error calculating categorical stats for {sas_variable_name}: {e}\")\n\n                # Create ColumnMetadata object\n                metadata = ColumnMetadata(\n                    label=label,\n                    sas_variable_name=sas_variable_name,\n                    section_name=section_name,\n                    section_number=section_number,\n                    module_number=module_number,\n                    question_number=question_number,\n                    column=column,\n                    type_of_variable=type_of_variable,\n                    question_prologue=question_prologue,\n                    question=question,\n                    value_lookup=get_value_lookup(table, df, sas_variable_name),\n                    computed= True if section_name == 'Calculated Variables' or section_name == 'Calculated Race Variables' else False,\n                    html_name=html_name,\n                    statistics=statistics\n                )\n\n                metadata_dict[sas_variable_name] = metadata\n\n        except Exception as e:\n            # Skip cells that don't parse correctly but show problems\n            print(e)\n\n    return metadata_dict",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-06T23:06:48.071516Z"
    }
   },
   "source": "bfrss_metadata = parse_codebook_html(Path(BFRSS_CODEBOOK_PATH), bfrss_raw_df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_nameIDX1\n",
      "html_nameIDX2\n",
      "html_nameIDX3\n",
      "html_nameIDX4\n",
      "html_nameIDX5\n",
      "html_nameIDX6\n",
      "html_nameIDX7\n",
      "html_nameIDX8\n",
      "html_nameIDX9\n",
      "html_nameIDX10\n",
      "html_nameIDX11\n",
      "html_nameIDX12\n",
      "html_nameIDX13\n",
      "html_nameIDX14\n",
      "html_nameIDX15\n",
      "html_nameIDX16\n",
      "html_nameIDX17\n",
      "html_nameIDX18\n",
      "html_nameIDX20\n",
      "html_nameIDX21\n",
      "html_nameIDX22\n",
      "html_nameIDX23\n",
      "html_nameIDX24\n",
      "html_nameIDX26\n",
      "html_nameIDX27\n",
      "html_nameIDX28\n",
      "html_nameIDX29\n",
      "html_nameIDX30\n",
      "html_nameIDX31\n",
      "html_nameIDX32\n",
      "html_nameIDX33\n",
      "html_nameIDX34\n",
      "html_nameIDX35\n",
      "html_nameIDX36\n",
      "html_nameIDX37\n",
      "html_nameIDX38\n",
      "html_nameIDX39\n",
      "html_nameIDX40\n",
      "html_nameIDX41\n",
      "html_nameIDX42\n",
      "html_nameIDX43\n",
      "html_nameIDX44\n",
      "html_nameIDX45\n",
      "html_nameIDX46\n",
      "html_nameIDX47\n",
      "html_nameIDX48\n",
      "html_nameIDX49\n",
      "html_nameIDX50\n",
      "html_nameIDX51\n",
      "html_nameIDX52\n",
      "html_nameIDX53\n",
      "html_nameIDX54\n",
      "html_nameIDX55\n",
      "html_nameIDX56\n",
      "html_nameIDX57\n",
      "html_nameIDX58\n",
      "html_nameIDX59\n",
      "html_nameIDX60\n",
      "html_nameIDX61\n",
      "html_nameIDX62\n",
      "html_nameIDX63\n",
      "html_nameIDX64\n",
      "html_nameIDX65\n",
      "html_nameIDX66\n",
      "html_nameIDX67\n",
      "html_nameIDX68\n",
      "html_nameIDX69\n",
      "html_nameIDX70\n",
      "html_nameIDX71\n",
      "html_nameIDX72\n",
      "html_nameIDX73\n",
      "html_nameIDX74\n",
      "html_nameIDX75\n",
      "html_nameIDX76\n",
      "html_nameIDX77\n",
      "html_nameIDX78\n",
      "html_nameIDX79\n",
      "html_nameIDX80\n",
      "html_nameIDX81\n",
      "html_nameIDX82\n",
      "html_nameIDX83\n",
      "html_nameIDX84\n",
      "html_nameIDX85\n",
      "html_nameIDX86\n",
      "html_nameIDX87\n",
      "html_nameIDX88\n",
      "html_nameIDX89\n",
      "html_nameIDX90\n",
      "html_nameIDX91\n",
      "html_nameIDX92\n",
      "html_nameIDX93\n",
      "html_nameIDX94\n",
      "html_nameIDX95\n",
      "html_nameIDX96\n",
      "html_nameIDX97\n",
      "html_nameIDX98\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.768110Z",
     "start_time": "2025-06-06T21:32:02.765218Z"
    }
   },
   "source": [
    "# Display the number of columns parsed\n",
    "print(f\"Parsed {len(bfrss_metadata)} column definitions from the codebook\")\n",
    "\n",
    "# Show a sample of the metadata\n",
    "sample_keys = list(bfrss_metadata.keys())[:5]\n",
    "for key in sample_keys:\n",
    "    metadata = bfrss_metadata[key]\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Label: {metadata.label}\")\n",
    "    print(f\"  Question: {metadata.question}\")\n",
    "    print(f\"  Column: {metadata.column}\")\n",
    "    print(f\"  Type: {metadata.type_of_variable}\")\n",
    "    print(f\"  Computed: {metadata.computed}\")\n",
    "    print(f\"  Section Name: {metadata.section_name}\")\n",
    "    print(f\"  Section Number: {metadata.section_number}\")\n",
    "    print(f\"  Question Number: {metadata.question_number}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 344 column definitions from the codebook\n",
      "\n",
      "_STATE:\n",
      "  Label: State FIPS Code\n",
      "  Question: State FIPS Code\n",
      "  Column: 1-2\n",
      "  Type: Num\n",
      "  Computed: False\n",
      "  Section Name: Record Identification\n",
      "  Section Number: 0\n",
      "  Question Number: 1\n",
      "\n",
      "FMONTH:\n",
      "  Label: File Month\n",
      "  Question: File Month\n",
      "  Column: 17-18\n",
      "  Type: Num\n",
      "  Computed: False\n",
      "  Section Name: Record Identification\n",
      "  Section Number: 0\n",
      "  Question Number: 8\n",
      "\n",
      "IDATE:\n",
      "  Label: Interview Date\n",
      "  Question: Interview Date\n",
      "  Column: 19-26\n",
      "  Type: Char\n",
      "  Computed: False\n",
      "  Section Name: Record Identification\n",
      "  Section Number: 0\n",
      "  Question Number: 9\n",
      "\n",
      "IMONTH:\n",
      "  Label: Interview Month\n",
      "  Question: Interview Month\n",
      "  Column: 19-20\n",
      "  Type: Char\n",
      "  Computed: False\n",
      "  Section Name: Record Identification\n",
      "  Section Number: 0\n",
      "  Question Number: 10\n",
      "\n",
      "IDAY:\n",
      "  Label: Interview Day\n",
      "  Question: Interview Day\n",
      "  Column: 21-22\n",
      "  Type: Char\n",
      "  Computed: False\n",
      "  Section Name: Record Identification\n",
      "  Section Number: 0\n",
      "  Question Number: 11\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgwFJt3YNBjQ"
   },
   "source": [
    "# Metadata Documentation\n",
    "Notes and examples of the metadata extraction:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IGcHPEctN3yb",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.789469Z",
     "start_time": "2025-06-06T21:32:02.785949Z"
    }
   },
   "source": [
    "print(f\"Total columns in dataframe: {len(bfrss_raw_df.columns)}\")\n",
    "print(f\"Total metadata parsed: {len(bfrss_metadata)}\")\n",
    "print(f\"Coverage: {len(bfrss_metadata) / len(bfrss_raw_df.columns) * 100:.1f}%\")\n",
    "\n",
    "# Check which columns don't have metadata\n",
    "missing_metadata = [col for col in bfrss_raw_df.columns if col not in bfrss_metadata]\n",
    "print(f\"\\nColumns without metadata: {len(missing_metadata)}\")\n",
    "if missing_metadata:\n",
    "    print(\"First 10 missing:\", missing_metadata[:10])\n",
    "print(\"Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in dataframe: 350\n",
      "Total metadata parsed: 344\n",
      "Coverage: 98.3%\n",
      "\n",
      "Columns without metadata: 7\n",
      "First 10 missing: ['LNDSXBRT', 'CELSXBRT', 'BIRTHSEX', 'TRNSGNDR', 'USEMRJN4', 'RCSGEND1', 'RCSXBRTH']\n",
      "Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUSQ1RmqOssx"
   },
   "source": [
    "## Understanding the Friendly Mapping Feature\n",
    "(note I generated the following docs and examples with ChatGPT, but I've vetted all of it)\n",
    "\n",
    "The metadata parser includes a powerful \"friendly mapping\" feature that translates numeric codes in the dataset to their human-readable descriptions. This is particularly useful for categorical variables where numeric codes represent specific responses.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "Each `ColumnMetadata` object contains a `value_lookup` dictionary that maps numeric values (or None) to their text descriptions. This mapping is automatically extracted from the codebook HTML file during parsing.\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "1. **`value_lookup` dictionary**: Found in each `ColumnMetadata` object\n",
    "   - Keys: Numeric codes (int) or None\n",
    "   - Values: Human-readable descriptions (str)\n",
    "\n",
    "2. **Automatic extraction**: The `get_value_lookup()` function in `parser.py` extracts these mappings from HTML tables in the codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gODrkHvrTg-u"
   },
   "source": [
    "### Example 1: Understanding what values mean for a specific column"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0rJpt2FIOttO",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.813972Z",
     "start_time": "2025-06-06T21:32:02.811365Z"
    }
   },
   "source": "# Example 1: Understanding what values mean for a specific column\n# Let's look at the _STATE column which has distinct state codes\n\nstate_metadata = bfrss_metadata['_STATE']\nprint(f\"Column: {state_metadata.sas_variable_name}\")\nprint(f\"Label: {state_metadata.label}\")\nprint(f\"Question: {state_metadata.question}\")\nprint(f\"\\nSample of value mappings (first 10):\")\n\n# Show first 10 state mappings\nfor i, val_def in enumerate(state_metadata.value_lookup[:10]):\n    if isinstance(val_def, ValueRange):\n        if val_def.start == val_def.end:\n            print(f\"  {val_def.start}: {val_def.description}\")\n        else:\n            print(f\"  {val_def.start}-{val_def.end}: {val_def.description}\")\n    else:\n        print(f\"  [Non-numeric]: {val_def.description}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V21re5obTSh5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNl8M6BgTppS"
   },
   "source": [
    "### Example 2: Translating values in your data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XxFI_rkHPEge",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.842762Z",
     "start_time": "2025-06-06T21:32:02.834391Z"
    }
   },
   "source": "# Example 2: Translating values in your data\n# Let's translate some actual STATE values from the dataframe\n\n# Get a sample of state values\nsample_values = bfrss_raw_df['_STATE'].value_counts().head(10)\nprint(\"Top 10 states by number of respondents:\\n\")\n\nfor value, count in sample_values.items():\n    # Get the description from value_lookup\n    description = \"Unknown\"\n    if not pd.isna(value):\n        value_int = int(value)\n        for val_def in state_metadata.value_lookup:\n            if isinstance(val_def, ValueRange) and val_def.start <= value_int <= val_def.end:\n                description = val_def.description\n                break\n    \n    print(f\"Code {int(value)}: {description} (Count: {count:,})\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ2PT79QTvWq"
   },
   "source": [
    "### Example 3: Creating a mapping function for easy translation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3g1Yxo9qO7Jt",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.981920Z",
     "start_time": "2025-06-06T21:32:02.859803Z"
    }
   },
   "source": "# Example 3: Creating a mapping function for easy translation\ndef translate_column_values(df, column_name, metadata_dict):\n    \"\"\"\n    Translate numeric codes to descriptions for a specific column.\n\n    Args:\n        df: The dataframe containing the data\n        column_name: Name of the column to translate\n        metadata_dict: Dictionary of column metadata\n\n    Returns:\n        Pandas Series with translated values\n    \"\"\"\n    if column_name not in metadata_dict:\n        print(f\"No metadata found for column: {column_name}\")\n        return df[column_name]\n\n    metadata = metadata_dict[column_name]\n\n    # Create translation function\n    def translate(value):\n        if pd.isna(value):\n            return \"Missing\"\n        \n        value_int = int(value) if isinstance(value, (int, float)) else None\n        if value_int is not None:\n            for val_def in metadata.value_lookup:\n                if isinstance(val_def, ValueRange) and val_def.start <= value_int <= val_def.end:\n                    return val_def.description\n        \n        return f\"Unknown code: {value}\"\n\n    return df[column_name].apply(translate)\n\n# Example usage - translate STATE codes\nbfrss_raw_df['STATE_NAME'] = translate_column_values(bfrss_raw_df, '_STATE', bfrss_metadata)\n\n# Show sample\nprint(\"Sample of translated state values:\")\nprint(bfrss_raw_df[['_STATE', 'STATE_NAME']].head(10))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAj4ILpoTzGG"
   },
   "source": [
    "### Example 4: Working with columns that have ranges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z3GMA7-BPWDz",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:02.995962Z",
     "start_time": "2025-06-06T21:32:02.993529Z"
    }
   },
   "source": "# Example 4: Working with columns that have ranges\n# Now let's test with POORHLTH which has a range value \"1 - 30\"\npoorhlth_metadata = bfrss_metadata['POORHLTH']\nprint(f\"Column: {poorhlth_metadata.sas_variable_name}\")\nprint(f\"Label: {poorhlth_metadata.label}\")\n\n# Check value mappings\nprint(f\"\\nValue mappings:\")\nfor val_def in poorhlth_metadata.value_lookup:\n    if isinstance(val_def, ValueRange):\n        if val_def.start == val_def.end:\n            print(f\"  {val_def.start}: {val_def.description} (Count: {val_def.count})\")\n        else:\n            print(f\"  {val_def.start}-{val_def.end}: {val_def.description} (Count: {val_def.count})\")\n    else:\n        print(f\"  [Non-numeric]: {val_def.description}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEdPwWOXT9sX"
   },
   "source": [
    "### Example 5: Batch translation of multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G-WvLDeMPiXj",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:03.367591Z",
     "start_time": "2025-06-06T21:32:03.021609Z"
    }
   },
   "source": [
    "# Example 5: Batch translation of multiple columns\n",
    "# This example shows how to efficiently translate multiple columns at once\n",
    "\n",
    "def batch_translate_columns(df, column_list, metadata_dict):\n",
    "    \"\"\"\n",
    "    Translate multiple columns from numeric codes to descriptions.\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe containing the data\n",
    "        column_list: List of column names to translate\n",
    "        metadata_dict: Dictionary of column metadata\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of translated series\n",
    "    \"\"\"\n",
    "    translated = {}\n",
    "\n",
    "    for col in column_list:\n",
    "        if col in metadata_dict and col in df.columns:\n",
    "            translated[f\"{col}_DESC\"] = translate_column_values(df, col, metadata_dict)\n",
    "            print(f\"Translated {col}\")\n",
    "        else:\n",
    "            print(f\"Skipped {col} (not found in metadata or dataframe)\")\n",
    "\n",
    "    return translated\n",
    "\n",
    "# Translate several categorical columns\n",
    "columns_to_translate = ['_STATE', 'FMONTH', 'DISPCODE', 'SEX1']\n",
    "translations = batch_translate_columns(bfrss_raw_df, columns_to_translate, bfrss_metadata)\n",
    "\n",
    "# Add translations to dataframe\n",
    "for col_name, translated_series in translations.items():\n",
    "    bfrss_raw_df[col_name] = translated_series\n",
    "\n",
    "# Show sample of multiple translations\n",
    "print(\"\\nSample of translated data:\")\n",
    "original_cols = columns_to_translate[:3]  # Show first 3\n",
    "desc_cols = [f\"{col}_DESC\" for col in original_cols]\n",
    "print(bfrss_raw_df[original_cols + desc_cols].head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated _STATE\n",
      "Translated FMONTH\n",
      "Translated DISPCODE\n",
      "Skipped SEX1 (not found in metadata or dataframe)\n",
      "\n",
      "Sample of translated data:\n",
      "   _STATE  FMONTH  DISPCODE _STATE_DESC FMONTH_DESC        DISPCODE_DESC\n",
      "0     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "1     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "2     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "3     1.0     1.0    1100.0     Alabama     January  Completed Interview\n",
      "4     1.0     1.0    1100.0     Alabama     January  Completed Interview\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjzzVNlTT_71"
   },
   "source": [
    "### Example 6: Getting columns by Section Name"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Example 7: Using the new statistics feature\n\nThe updated parser now automatically calculates statistics for each column during parsing. This includes:\n- For numeric columns: mean, std, min, max, quartiles\n- For categorical columns: value counts and top values with descriptions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 7: Accessing pre-calculated statistics\n# Let's examine the statistics for a numeric column\nageg5yr_metadata = bfrss_metadata['_AGEG5YR']\nprint(f\"Column: {ageg5yr_metadata.sas_variable_name}\")\nprint(f\"Label: {ageg5yr_metadata.label}\")\nprint(f\"Type: {ageg5yr_metadata.type_of_variable}\")\n\nif ageg5yr_metadata.statistics:\n    stats = ageg5yr_metadata.statistics\n    print(f\"\\nStatistics:\")\n    print(f\"  Count: {stats.count:,}\")\n    print(f\"  Null Count: {stats.null_count:,}\")\n    print(f\"  Unique Values: {stats.unique_count}\")\n    \n    if hasattr(stats, 'mean'):  # NumericStatistics\n        print(f\"  Mean: {stats.mean:.2f}\")\n        print(f\"  Std Dev: {stats.std:.2f}\")\n        print(f\"  Min: {stats.min}\")\n        print(f\"  25th percentile: {stats.q25}\")\n        print(f\"  Median: {stats.median}\")\n        print(f\"  75th percentile: {stats.q75}\")\n        print(f\"  Max: {stats.max}\")\n\n# Let's also look at a categorical column\nstate_stats = bfrss_metadata['_STATE'].statistics\nif state_stats and hasattr(state_stats, 'top_values'):\n    print(f\"\\n\\nTop states by response count:\")\n    for item in state_stats.top_values[:5]:\n        print(f\"  {item['description']}: {item['count']:,} responses\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Example 8: Value counts in ranges",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 8: The new parser calculates counts for each value range\n# This is particularly useful for understanding data distribution\n\npoorhlth_metadata = bfrss_metadata['POORHLTH']\nprint(f\"Column: {poorhlth_metadata.sas_variable_name}\")\nprint(f\"Label: {poorhlth_metadata.label}\")\nprint(f\"\\nValue distribution:\")\n\ntotal_responses = 0\nfor val_def in poorhlth_metadata.value_lookup:\n    if isinstance(val_def, ValueRange) and val_def.count > 0:\n        total_responses += val_def.count\n        if val_def.start == val_def.end:\n            print(f\"  Value {val_def.start} ({val_def.description}): {val_def.count:,} responses\")\n        else:\n            print(f\"  Range {val_def.start}-{val_def.end} ({val_def.description}): {val_def.count:,} responses\")\n\nprint(f\"\\nTotal responses captured in value ranges: {total_responses:,}\")\n\n# We can also check the column's overall statistics\nif poorhlth_metadata.statistics:\n    print(f\"Total non-null responses: {poorhlth_metadata.statistics.count:,}\")\n    print(f\"Null/missing responses: {poorhlth_metadata.statistics.null_count:,}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Degwj_IgbGK7",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:03.382119Z",
     "start_time": "2025-06-06T21:32:03.379790Z"
    }
   },
   "source": [
    "# Simple example: Get all column names for 'Calculated Variables' section\n",
    "calculated_columns = [col for col, meta in bfrss_metadata.items()\n",
    "                     if meta.section_name == 'Calculated Variables']\n",
    "\n",
    "print(f\"Columns in 'Calculated Variables' section: {len(calculated_columns)}\")\n",
    "print(f\"\\nColumn names: {calculated_columns}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 'Calculated Variables' section: 70\n",
      "\n",
      "Column names: ['_RFHLTH', '_PHYS14D', '_MENT14D', '_HLTHPL1', '_HCVU653', '_TOTINDA', 'METVL12_', 'METVL22_', 'MAXVO21_', 'FC601_', 'ACTIN13_', 'ACTIN23_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC12', '_MINAC22', 'STRFREQ_', 'PAMISS3_', 'PAMIN13_', 'PAMIN23_', 'PA3MIN_', 'PAVIG13_', 'PAVIG23_', 'PA3VIGM_', '_PACAT3', '_PAINDX3', '_PA150R4', '_PA300R4', '_PA30023', '_PASTRNG', '_PAREC3', '_PASTAE3', '_RFHYPE6', '_CHOLCH3', '_RFCHOL3', '_MICHD', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR2', '_SEX', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG1', '_SMOKER3', '_RFSMOK3', '_CURECI2', 'DRNKANY6', 'DROCDY4_', '_RFBING6', '_DRNKWK2', '_RFDRHV8', '_FLSHOT7', '_PNEUMO3', '_AIDTST4', '_RFSEAT2', '_RFSEAT3', '_DRNKDRV']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GjWCW3A2hTPr",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:03.405722Z",
     "start_time": "2025-06-06T21:32:03.403770Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMTzF2nXbXaL"
   },
   "source": [
    "# Kelly Scratch\n",
    "\n",
    "- making own copies of data for experimentation: k_df, k_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agXugo3khXu5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "yW4EYaNthYdj",
    "outputId": "f06cbe53-a570-4d97-8403-e04945ed7d20",
    "ExecuteTime": {
     "end_time": "2025-06-06T21:32:03.969648Z",
     "start_time": "2025-06-06T21:32:03.419512Z"
    }
   },
   "source": [
    "k_df = bfrss_raw_df.copy()\n",
    "k_metadata = bfrss_metadata.copy()\n",
    "\n",
    "# Metadata Tests\n",
    "##\n",
    "\n",
    "k_m_df = pd.DataFrame.from_dict(k_metadata, orient='index')\n",
    "k_m_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 344 entries, _STATE to _DRNKDRV\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       344 non-null    object\n",
      " 1   1       344 non-null    object\n",
      " 2   2       344 non-null    object\n",
      " 3   3       344 non-null    object\n",
      " 4   4       344 non-null    object\n",
      " 5   5       344 non-null    object\n",
      " 6   6       344 non-null    object\n",
      " 7   7       344 non-null    object\n",
      " 8   8       344 non-null    object\n",
      " 9   9       344 non-null    object\n",
      " 10  10      344 non-null    object\n",
      " 11  11      344 non-null    object\n",
      "dtypes: object(12)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iWGgG0Pbaw0"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YMzEMIm7Iuw6"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
