{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sksizer/dat490/blob/main/BFRSS_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMzEMIm7Iuw6"
   },
   "source": [
    "# Environment Setup\n",
    "- check env\n",
    "- set and test paths for data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Set up environment and paths\n",
    "if is_colab():\n",
    "    print(\"Running in Google Colab\")\n",
    "    \n",
    "    # Clone the repository if not already cloned\n",
    "    if not os.path.exists('dat490'):\n",
    "        import subprocess\n",
    "        print(\"Cloning repository...\")\n",
    "        subprocess.run(['git', 'clone', 'https://github.com/sksizer/dat490.git'], check=True)\n",
    "        print(\"Repository cloned successfully\")\n",
    "    \n",
    "    # Add the repository to Python path for imports\n",
    "    sys.path.insert(0, '/content/dat490')\n",
    "    \n",
    "    # Set paths to use data from the cloned repository\n",
    "    BFRSS_DATA_PATH = 'dat490/data/LLCP2023.parquet'\n",
    "    BFRSS_CODEBOOK_PATH = 'dat490/data/codebook_USCODE23_LLCP_021924.HTML'\n",
    "    BFRSS_DESC_PATH = 'dat490/data/LLCP2023_desc.parquet'  # Additional metadata file if needed\n",
    "else:\n",
    "    print(\"Running in local environment\")\n",
    "    \n",
    "    # Add parent directory to path for dat490 module imports\n",
    "    sys.path.insert(0, os.path.abspath('..'))\n",
    "    \n",
    "    # Use local data paths\n",
    "    BFRSS_DATA_PATH = '../data/LLCP2023.parquet'\n",
    "    BFRSS_CODEBOOK_PATH = '../data/codebook_USCODE23_LLCP_021924.HTML'\n",
    "    BFRSS_DESC_PATH = '../data/LLCP2023_desc.parquet'  # Additional metadata file if needed\n",
    "\n",
    "# Verify files exist\n",
    "print(f\"\\\\nData path: {BFRSS_DATA_PATH}\")\n",
    "print(f\"Codebook path: {BFRSS_CODEBOOK_PATH}\")\n",
    "\n",
    "if not os.path.exists(BFRSS_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Data file not found at {BFRSS_DATA_PATH}\")\n",
    "\n",
    "if not os.path.exists(BFRSS_CODEBOOK_PATH):\n",
    "    raise FileNotFoundError(f\"Codebook file not found at {BFRSS_CODEBOOK_PATH}\")\n",
    "\n",
    "print(\"\\\\nAll required files found!\")\n",
    "logger.info('Environment setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gcIaBDZpH8O"
   },
   "outputs": [],
   "source": [
    "# Load Data and Metadata\n",
    "- The new BFRSS wrapper provides a single interface to access both data and metadata\n",
    "- It automatically handles file paths, lazy loading, and metadata parsing\n",
    "- By default, we load the _DESC columns which contain the categorized version of the BRFSS data\n",
    "- The metadata generation will skip _DESC columns to avoid duplication with value_ranges information"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eckrUOR1ilCW"
   },
   "outputs": [],
   "source": [
    "# Load BFRSS data and metadata using the new wrapper\n",
    "from dat490 import load_bfrss\n",
    "\n",
    "# Single function call to load everything\n",
    "# By default, this loads the _DESC columns in the DataFrame\n",
    "# but excludes them from metadata generation to avoid duplication\n",
    "bfrss = load_bfrss(exclude_desc_columns=True)\n",
    "\n",
    "# Get a copy of the raw DataFrame (includes _DESC columns)\n",
    "bfrss_raw_df = bfrss.cloneDF()\n",
    "print(f\"DataFrame shape: {bfrss_raw_df.shape}\")\n",
    "print(f\"_DESC columns: {len([col for col in bfrss_raw_df.columns if col.endswith('_DESC')])}\")\n",
    "bfrss_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfrss_raw_df.loc[:,'_AGEG5YR'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parser module is already imported by the BFRSS wrapper\n",
    "# but we can import specific classes if needed for type hints or direct use\n",
    "try:\n",
    "    from dat490.parser import (\n",
    "        ColumnMetadata, \n",
    "        ValueDef,\n",
    "        ValueRange,\n",
    "        ColumnStatistics,\n",
    "        NumericStatistics,\n",
    "        CategoricalStatistics\n",
    "    )\n",
    "    print(\"Parser classes available for direct use\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing parser classes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get the metadata dictionary from BFRSS wrapper\n",
    "bfrss_metadata = bfrss.cloneMetadata()\n",
    "\n",
    "# The metadata is already parsed and ready to use\n",
    "print(f\"Total metadata entries: {len(bfrss_metadata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate BFRSS wrapper utility methods\n",
    "\n",
    "# 1. Direct value lookup\n",
    "state_1_desc = bfrss.lookup_value('_STATE', 1)\n",
    "print(f\"State code 1 = {state_1_desc}\")\n",
    "\n",
    "# 2. Get all sections\n",
    "sections = bfrss.get_sections()\n",
    "print(f\"\\nTotal sections: {len(sections)}\")\n",
    "print(\"First 5 sections:\", sections[:5])\n",
    "\n",
    "# 3. Get columns by section\n",
    "calc_columns = bfrss.get_columns_by_section('Calculated Variables')\n",
    "print(f\"\\nCalculated Variables section has {len(calc_columns)} columns\")\n",
    "print(\"First 5:\", calc_columns[:5])\n",
    "\n",
    "# 4. Search for columns\n",
    "diabetes_columns = bfrss.search_columns('diabetes')\n",
    "print(f\"\\nColumns mentioning 'diabetes': {len(diabetes_columns)}\")\n",
    "for col in diabetes_columns[:3]:\n",
    "    meta = bfrss.get_column_info(col)\n",
    "    print(f\"  {col}: {meta.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note about _DESC columns\n",
    "# The LLCP2023.parquet file contains both raw numeric codes AND _DESC columns\n",
    "# The _DESC columns have the human-readable categorized versions of the data\n",
    "# These are particularly useful for analysis and visualization\n",
    "\n",
    "# List all _DESC columns\n",
    "desc_columns = [col for col in bfrss_raw_df.columns if col.endswith('_DESC')]\n",
    "print(f\"Total _DESC columns in DataFrame: {len(desc_columns)}\")\n",
    "print(f\"First 10 _DESC columns: {desc_columns[:10]}\")\n",
    "\n",
    "# Example: Compare raw vs _DESC for a specific column\n",
    "if '_AGEG5YR' in bfrss_raw_df.columns and '_AGEG5YR_DESC' in bfrss_raw_df.columns:\n",
    "    print(\"\\nExample: Age group comparison\")\n",
    "    comparison = bfrss_raw_df[['_AGEG5YR', '_AGEG5YR_DESC']].value_counts().head(10)\n",
    "    print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of columns parsed\n",
    "print(f\"Parsed {len(bfrss_metadata)} column definitions from the codebook\")\n",
    "\n",
    "# Show a sample of the metadata\n",
    "sample_keys = list(bfrss_metadata.keys())[:5]\n",
    "for key in sample_keys:\n",
    "    metadata = bfrss_metadata[key]\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Label: {metadata.label}\")\n",
    "    print(f\"  Question: {metadata.question}\")\n",
    "    print(f\"  Column: {metadata.column}\")\n",
    "    print(f\"  Type: {metadata.type_of_variable}\")\n",
    "    print(f\"  Computed: {metadata.computed}\")\n",
    "    print(f\"  Section Name: {metadata.section_name}\")\n",
    "    print(f\"  Section Number: {metadata.section_number}\")\n",
    "    print(f\"  Question Number: {metadata.question_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgwFJt3YNBjQ"
   },
   "source": [
    "# Metadata Documentation\n",
    "Notes and examples of the metadata extraction:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGcHPEctN3yb"
   },
   "outputs": [],
   "source": [
    "print(f\"Total columns in dataframe: {len(bfrss_raw_df.columns)}\")\n",
    "print(f\"Total metadata parsed: {len(bfrss_metadata)}\")\n",
    "print(f\"Coverage: {len(bfrss_metadata) / len(bfrss_raw_df.columns) * 100:.1f}%\")\n",
    "\n",
    "# Check which columns don't have metadata\n",
    "missing_metadata = [col for col in bfrss_raw_df.columns if col not in bfrss_metadata]\n",
    "print(f\"\\nColumns without metadata: {len(missing_metadata)}\")\n",
    "if missing_metadata:\n",
    "    print(\"First 10 missing:\", missing_metadata[:10])\n",
    "print(\"Note: There is data for these columns but no metadata is available, likely purged bc of policy changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BFRSS Wrapper Utility Methods\n",
    "\n",
    "The BFRSS wrapper provides several convenient methods for working with the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUSQ1RmqOssx"
   },
   "source": [
    "## Understanding the Friendly Mapping Feature\n",
    "(note I generated the following docs and examples with ChatGPT, but I've vetted all of it)\n",
    "\n",
    "The metadata parser includes a powerful \"friendly mapping\" feature that translates numeric codes in the dataset to their human-readable descriptions. This is particularly useful for categorical variables where numeric codes represent specific responses.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "Each `ColumnMetadata` object contains a `value_lookup` dictionary that maps numeric values (or None) to their text descriptions. This mapping is automatically extracted from the codebook HTML file during parsing.\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "1. **`value_lookup` dictionary**: Found in each `ColumnMetadata` object\n",
    "   - Keys: Numeric codes (int) or None\n",
    "   - Values: Human-readable descriptions (str)\n",
    "\n",
    "2. **Automatic extraction**: The `get_value_lookup()` function in `parser.py` extracts these mappings from HTML tables in the codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gODrkHvrTg-u"
   },
   "source": [
    "### Example 1: Understanding what values mean for a specific column"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0rJpt2FIOttO"
   },
   "outputs": [],
   "source": [
    "# Example 1: Understanding what values mean for a specific column\n",
    "# Let's look at the _STATE column which has distinct state codes\n",
    "\n",
    "state_metadata = bfrss_metadata['_STATE']\n",
    "print(f\"Column: {state_metadata.sas_variable_name}\")\n",
    "print(f\"Label: {state_metadata.label}\")\n",
    "print(f\"Question: {state_metadata.question}\")\n",
    "print(f\"\\nSample of value mappings (first 10):\")\n",
    "\n",
    "# Show first 10 state mappings using value_ranges\n",
    "for i, val_def in enumerate(state_metadata.value_ranges[:10]):\n",
    "    if isinstance(val_def, ValueRange):\n",
    "        if val_def.start == val_def.end:\n",
    "            print(f\"  {val_def.start}: {val_def.description}\")\n",
    "        else:\n",
    "            print(f\"  {val_def.start}-{val_def.end}: {val_def.description}\")\n",
    "    else:\n",
    "        print(f\"  [Non-numeric]: {val_def.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V21re5obTSh5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNl8M6BgTppS"
   },
   "source": [
    "### Example 2: Translating values in your data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XxFI_rkHPEge"
   },
   "outputs": [],
   "source": [
    "# Example 2: Translating values in your data\n",
    "# Let's translate some actual STATE values from the dataframe\n",
    "\n",
    "# Get a sample of state values\n",
    "sample_values = bfrss_raw_df['_STATE'].value_counts().head(10)\n",
    "print(\"Top 10 states by number of respondents:\\n\")\n",
    "\n",
    "for value, count in sample_values.items():\n",
    "    # Get the description from value_ranges\n",
    "    description = \"Unknown\"\n",
    "    if not pd.isna(value):\n",
    "        value_int = int(value)\n",
    "        for val_def in state_metadata.value_ranges:\n",
    "            if isinstance(val_def, ValueRange) and val_def.start <= value_int <= val_def.end:\n",
    "                description = val_def.description\n",
    "                break\n",
    "    \n",
    "    print(f\"Code {int(value)}: {description} (Count: {count:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ2PT79QTvWq"
   },
   "source": [
    "### Example 3: Creating a mapping function for easy translation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3g1Yxo9qO7Jt"
   },
   "outputs": [],
   "source": [
    "# Example 3: Creating a mapping function for easy translation\n",
    "def translate_column_values(df, column_name, metadata_dict):\n",
    "    \"\"\"\n",
    "    Translate numeric codes to descriptions for a specific column.\n",
    "    Updated to work with value_ranges instead of value_lookup.\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe containing the data\n",
    "        column_name: Name of the column to translate\n",
    "        metadata_dict: Dictionary of column metadata\n",
    "\n",
    "    Returns:\n",
    "        Pandas Series with translated values\n",
    "    \"\"\"\n",
    "    if column_name not in metadata_dict:\n",
    "        print(f\"No metadata found for column: {column_name}\")\n",
    "        return df[column_name]\n",
    "\n",
    "    metadata = metadata_dict[column_name]\n",
    "\n",
    "    # Create translation function\n",
    "    def translate(value):\n",
    "        if pd.isna(value):\n",
    "            return \"Missing\"\n",
    "        \n",
    "        value_int = int(value) if isinstance(value, (int, float)) else None\n",
    "        if value_int is not None:\n",
    "            # Use value_ranges instead of value_lookup\n",
    "            for val_def in metadata.value_ranges:\n",
    "                if isinstance(val_def, ValueRange) and val_def.start <= value_int <= val_def.end:\n",
    "                    return val_def.description\n",
    "        \n",
    "        return f\"Unknown code: {value}\"\n",
    "\n",
    "    return df[column_name].apply(translate)\n",
    "\n",
    "# Example usage - translate STATE codes\n",
    "bfrss_raw_df['STATE_NAME'] = translate_column_values(bfrss_raw_df, '_STATE', bfrss_metadata)\n",
    "\n",
    "# Show sample\n",
    "print(\"Sample of translated state values:\")\n",
    "print(bfrss_raw_df[['_STATE', 'STATE_NAME']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAj4ILpoTzGG"
   },
   "source": [
    "### Example 4: Working with columns that have ranges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z3GMA7-BPWDz"
   },
   "outputs": [],
   "source": [
    "# Example 4: Working with columns that have ranges\n",
    "# Now let's test with POORHLTH which has a range value \"1 - 30\"\n",
    "poorhlth_metadata = bfrss_metadata['POORHLTH']\n",
    "print(f\"Column: {poorhlth_metadata.sas_variable_name}\")\n",
    "print(f\"Label: {poorhlth_metadata.label}\")\n",
    "\n",
    "# Check value mappings using value_ranges\n",
    "print(f\"\\nValue mappings:\")\n",
    "for val_def in poorhlth_metadata.value_ranges:\n",
    "    if isinstance(val_def, ValueRange):\n",
    "        if val_def.start == val_def.end:\n",
    "            print(f\"  {val_def.start}: {val_def.description} (Count: {val_def.count})\")\n",
    "        else:\n",
    "            print(f\"  {val_def.start}-{val_def.end}: {val_def.description} (Count: {val_def.count})\")\n",
    "    else:\n",
    "        print(f\"  [Non-numeric]: {val_def.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEdPwWOXT9sX"
   },
   "source": [
    "### Example 5: Batch translation of multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-WvLDeMPiXj"
   },
   "outputs": [],
   "source": [
    "# Example 5: Batch translation of multiple columns\n",
    "# This example shows how to efficiently translate multiple columns at once\n",
    "\n",
    "def batch_translate_columns(df, column_list, metadata_dict):\n",
    "    \"\"\"\n",
    "    Translate multiple columns from numeric codes to descriptions.\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe containing the data\n",
    "        column_list: List of column names to translate\n",
    "        metadata_dict: Dictionary of column metadata\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of translated series\n",
    "    \"\"\"\n",
    "    translated = {}\n",
    "\n",
    "    for col in column_list:\n",
    "        if col in metadata_dict and col in df.columns:\n",
    "            translated[f\"{col}_DESC\"] = translate_column_values(df, col, metadata_dict)\n",
    "            print(f\"Translated {col}\")\n",
    "        else:\n",
    "            print(f\"Skipped {col} (not found in metadata or dataframe)\")\n",
    "\n",
    "    return translated\n",
    "\n",
    "# Translate several categorical columns\n",
    "columns_to_translate = ['_STATE', 'FMONTH', 'DISPCODE', 'SEX1']\n",
    "translations = batch_translate_columns(bfrss_raw_df, columns_to_translate, bfrss_metadata)\n",
    "\n",
    "# Add translations to dataframe\n",
    "for col_name, translated_series in translations.items():\n",
    "    bfrss_raw_df[col_name] = translated_series\n",
    "\n",
    "# Show sample of multiple translations\n",
    "print(\"\\nSample of translated data:\")\n",
    "original_cols = columns_to_translate[:3]  # Show first 3\n",
    "desc_cols = [f\"{col}_DESC\" for col in original_cols]\n",
    "print(bfrss_raw_df[original_cols + desc_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjzzVNlTT_71"
   },
   "source": [
    "### Example 6: Getting columns by Section Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Using the new statistics feature\n",
    "\n",
    "The updated parser now automatically calculates statistics for each column during parsing. This includes:\n",
    "- For numeric columns: mean, std, min, max, quartiles\n",
    "- For categorical columns: value counts and top values with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Accessing pre-calculated statistics\n",
    "# Let's examine the statistics for a numeric column\n",
    "ageg5yr_metadata = bfrss_metadata['_AGEG5YR']\n",
    "print(f\"Column: {ageg5yr_metadata.sas_variable_name}\")\n",
    "print(f\"Label: {ageg5yr_metadata.label}\")\n",
    "print(f\"Type: {ageg5yr_metadata.type_of_variable}\")\n",
    "\n",
    "if ageg5yr_metadata.statistics:\n",
    "    stats = ageg5yr_metadata.statistics\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Count: {stats.count:,}\")\n",
    "    print(f\"  Null Count: {stats.null_count:,}\")\n",
    "    print(f\"  Unique Values: {stats.unique_count}\")\n",
    "    \n",
    "    if hasattr(stats, 'mean'):  # NumericStatistics\n",
    "        print(f\"  Mean: {stats.mean:.2f}\")\n",
    "        print(f\"  Std Dev: {stats.std:.2f}\")\n",
    "        print(f\"  Min: {stats.min}\")\n",
    "        print(f\"  25th percentile: {stats.q25}\")\n",
    "        print(f\"  Median: {stats.median}\")\n",
    "        print(f\"  75th percentile: {stats.q75}\")\n",
    "        print(f\"  Max: {stats.max}\")\n",
    "\n",
    "# Let's also look at a categorical column\n",
    "state_stats = bfrss_metadata['_STATE'].statistics\n",
    "if state_stats and hasattr(state_stats, 'top_values'):\n",
    "    print(f\"\\n\\nTop states by response count:\")\n",
    "    for item in state_stats.top_values[:5]:\n",
    "        print(f\"  {item['description']}: {item['count']:,} responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: Value counts in ranges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: The new parser calculates counts for each value range\n",
    "# This is particularly useful for understanding data distribution\n",
    "\n",
    "poorhlth_metadata = bfrss_metadata['POORHLTH']\n",
    "print(f\"Column: {poorhlth_metadata.sas_variable_name}\")\n",
    "print(f\"Label: {poorhlth_metadata.label}\")\n",
    "print(f\"\\nValue distribution:\")\n",
    "\n",
    "total_responses = 0\n",
    "for val_def in poorhlth_metadata.value_ranges:\n",
    "    if isinstance(val_def, ValueRange) and val_def.count > 0:\n",
    "        total_responses += val_def.count\n",
    "        if val_def.start == val_def.end:\n",
    "            print(f\"  Value {val_def.start} ({val_def.description}): {val_def.count:,} responses\")\n",
    "        else:\n",
    "            print(f\"  Range {val_def.start}-{val_def.end} ({val_def.description}): {val_def.count:,} responses\")\n",
    "\n",
    "print(f\"\\nTotal responses captured in value ranges: {total_responses:,}\")\n",
    "\n",
    "# We can also check the column's overall statistics\n",
    "if poorhlth_metadata.statistics:\n",
    "    print(f\"Total non-null responses: {poorhlth_metadata.statistics.count:,}\")\n",
    "    print(f\"Null/missing responses: {poorhlth_metadata.statistics.null_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Degwj_IgbGK7"
   },
   "outputs": [],
   "source": [
    "# Simple example: Get all column names for 'Calculated Variables' section\n",
    "calculated_columns = [col for col, meta in bfrss_metadata.items()\n",
    "                     if meta.section_name == 'Calculated Variables']\n",
    "\n",
    "print(f\"Columns in 'Calculated Variables' section: {len(calculated_columns)}\")\n",
    "print(f\"\\nColumn names: {calculated_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjWCW3A2hTPr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMTzF2nXbXaL"
   },
   "source": [
    "# Kelly Scratch\n",
    "\n",
    "- making own copies of data for experimentation: k_df, k_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agXugo3khXu5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "yW4EYaNthYdj",
    "outputId": "f06cbe53-a570-4d97-8403-e04945ed7d20"
   },
   "outputs": [],
   "source": [
    "k_df = bfrss_raw_df.copy()\n",
    "k_metadata = bfrss_metadata.copy()\n",
    "\n",
    "# Metadata Tests\n",
    "##\n",
    "\n",
    "k_m_df = pd.DataFrame.from_dict(k_metadata, orient='index')\n",
    "k_m_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iWGgG0Pbaw0"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YMzEMIm7Iuw6"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
