{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Goal\n",
    "## Original Questions\n",
    "- Can we use Chronic Health Conditions to accurately predict Health Care Access?\n",
    "- Are there Demographic clusters that are disproportionately affected by Chronic Health Conditions?\n",
    "- Can unsupervised learning methods reveal distinct clusters that account for the bulk of Chronic Health Conditions?\n",
    "\n",
    "### Questions:\n",
    "- I have gotten a bit hung up bc as worded 2 and 3 seem to be asking same thing?\n",
    "- were there established chronic health conditions?\n",
    "- established demographic features?\n",
    "- what are the features used in RQ1, and RQ3?\n",
    "\n",
    "#### Rough Plan:\n",
    "Question: Refinement:\n",
    "Are there diagnostically useful demographic clusters that indicate chronic health conditions?\n",
    "- Are there demographic clusters that strongly indicate certain chronic health conditions?\n",
    "- Can we predict chronic health conditions from demographics, and how does a ML model compare with simpler cluster membership?\n",
    "\n",
    "##### Part 1: Clustering\n",
    "- Cluster the demographic features of the BRFSS data\n",
    "- Visualize clusters and prevalence of chronic health conditions within each cluster\n",
    "    - what chronic health conditions to use?\n",
    "    - VISUAL: Clustering results\n",
    "    - VISUAL:  Heatmaps of cluster membership vs chronic health conditions\n",
    "- Run statistical tests to determine if certain clusters are significantly more affected by chronic health conditions\n",
    "    - Translation - test the strength of correlation between cluster membership and chronic health conditions\n",
    "    - Does being a member of a cluster correlate with having a chronic health condition?\n",
    "#### Part 2: Prediction of Chronic Health Conditions From Demographics via DL Model. Inversion of Question 3\n",
    "- use cluster labels as features?\n",
    "- compare performance of a deep learning model vs simpler clustering membership\n",
    "\n",
    "\n",
    "\n",
    "### Misc\n",
    "- potential 'linchpin' variables given we are clustering on demographics (and ran random forest on demographics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import kmodes\n",
    "    print(\"kmodes already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing kmodes...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kmodes\"])\n",
    "    import kmodes\n",
    "    print(\"kmodes installed successfully\")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in str(get_ipython())\n",
    "\n",
    "# Set up environment and paths\n",
    "if is_colab():\n",
    "    print(\"Running in Google Colab\")\n",
    "\n",
    "    # Clone the repository if not already cloned\n",
    "    if not os.path.exists('dat490'):\n",
    "        import subprocess\n",
    "        print(\"Cloning repository...\")\n",
    "        subprocess.run(['git', 'clone', 'https://github.com/sksizer/dat490.git'], check=True)\n",
    "        print(\"Repository cloned successfully\")\n",
    "\n",
    "    # Add the repository to Python path for imports\n",
    "    sys.path.insert(0, '/content/dat490')\n",
    "\n",
    "    # Set paths to use data from the cloned repository\n",
    "    BFRSS_DATA_PATH = 'dat490/data/LLCP2023.parquet'\n",
    "    BFRSS_CODEBOOK_PATH = 'dat490/data/codebook_USCODE23_LLCP_021924.HTML'\n",
    "    BFRSS_DESC_PATH = 'dat490/data/LLCP2023_desc.parquet'  # Additional metadata file if needed\n",
    "else:\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "    # Add parent directory to path for dat490 module imports\n",
    "    sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "    # Use local data paths\n",
    "    BFRSS_DATA_PATH = '../data/LLCP2023.parquet'\n",
    "    BFRSS_CODEBOOK_PATH = '../data/codebook_USCODE23_LLCP_021924.HTML'\n",
    "    BFRSS_DESC_PATH = '../data/LLCP2023_desc.parquet'  # Additional metadata file if needed\n",
    "\n",
    "# Verify files exist\n",
    "print(f\"\\\\nData path: {BFRSS_DATA_PATH}\")\n",
    "print(f\"Codebook path: {BFRSS_CODEBOOK_PATH}\")\n",
    "\n",
    "if not os.path.exists(BFRSS_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Data file not found at {BFRSS_DATA_PATH}\")\n",
    "\n",
    "if not os.path.exists(BFRSS_CODEBOOK_PATH):\n",
    "    raise FileNotFoundError(f\"Codebook file not found at {BFRSS_CODEBOOK_PATH}\")\n",
    "\n",
    "print(\"\\\\nAll required files found!\")\n",
    "logger.info('Environment setup complete')\n",
    "\n",
    "##################################\n",
    "# Load BFRSS data and metadata using the new wrapper\n",
    "from dat490 import load_bfrss\n",
    "\n",
    "# Single function call to load everything\n",
    "# exclude_desc_columns=True will exclude _DESC columns from metadata generation\n",
    "bfrss = load_bfrss(exclude_desc_columns=True)\n",
    "\n",
    "# Get a copy of the raw DataFrame\n",
    "bfrss_raw_df = bfrss.cloneDF()\n",
    "bfrss_raw_df.info()\n",
    "\n",
    "DEMOGRAPHIC_FEATURE_COLUMNS = [\n",
    "    # Demographics section columns (13 total)\n",
    "    # Demographics section columns (13 total)\n",
    "    'MARITAL',    # https://singular-eclair-6a5a16.netlify.app/columns/MARITAL\n",
    "    'EDUCA',      # https://singular-eclair-6a5a16.netlify.app/columns/EDUCA\n",
    "    'RENTHOM1',   # https://singular-eclair-6a5a16.netlify.app/columns/RENTHOM1\n",
    "    'NUMHHOL4',   # https://singular-eclair-6a5a16.netlify.app/columns/NUMHHOL4\n",
    "    'NUMPHON4',   # https://singular-eclair-6a5a16.netlify.app/columns/NUMPHON4\n",
    "    'CPDEMO1C',   # https://singular-eclair-6a5a16.netlify.app/columns/CPDEMO1C\n",
    "    'VETERAN3',   # https://singular-eclair-6a5a16.netlify.app/columns/VETERAN3\n",
    "    'EMPLOY1',    # https://singular-eclair-6a5a16.netlify.app/columns/EMPLOY1\n",
    "    'CHILDREN',   # https://singular-eclair-6a5a16.netlify.app/columns/CHILDREN\n",
    "    'INCOME3',    # https://singular-eclair-6a5a16.netlify.app/columns/INCOME3\n",
    "    'PREGNANT',   # https://singular-eclair-6a5a16.netlify.app/columns/PREGNANT\n",
    "    'SEXVAR',    # https://singular-eclair-6a5a16.netlify.app/columns/SEXVAR\n",
    "    '_HISPANC', # https://singular-eclair-6a5a16.netlify.app/columns/_HISPANC # Calculated but not sure from what\n",
    "    '_CRACE1',    # https://singular-eclair-6a5a16.netlify.app/columns/_CRACE1 # Child race\n",
    "    '_IMPRACE',   # https://singular-eclair-6a5a16.netlify.app/columns/_IMPRACE\n",
    "    '_AGE80',     # https://singular-eclair-6a5a16.netlify.app/columns/_AGE80\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# K-Modes Analysis of BRFSS Data\n",
    "\n",
    "K-Modes clustering is an extension of K-Means designed for categorical data. Instead of using means to define cluster centers, K-Modes uses modes (most frequent values) and measures dissimilarity using the number of mismatches between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def kmode_analysis(df: pd.DataFrame, feature_cols: list, max_clusters: int = 6):\n",
    "    data = df[feature_cols].copy()\n",
    "\n",
    "    # Encode categorical variables\n",
    "    encoders = {}\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object' or data[col].dtype.name == 'category':\n",
    "            le = LabelEncoder()\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "            encoders[col] = le\n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "    # Elbow Method\n",
    "    cost = []\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        km = KModes(n_clusters=k, init='Huang', n_init=5, verbose=0)\n",
    "        km.fit_predict(data)\n",
    "        cost.append(km.cost_)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(1, max_clusters + 1), cost, marker='o')\n",
    "    plt.title('Elbow Method - Cost vs. Number of Clusters')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Fit the best model (you can tune n_clusters here if needed)\n",
    "    optimal_k = 2  # or set based on elbow result\n",
    "    km = KModes(n_clusters=optimal_k, init='Huang', n_init=5, verbose=0)\n",
    "    clusters = km.fit_predict(data)\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    # Cluster sizes\n",
    "    cluster_counts = df['Cluster'].value_counts().sort_index()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x=cluster_counts.index, y=cluster_counts.values)\n",
    "    plt.title('Cluster Size Distribution')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Number of Records')\n",
    "    plt.show()\n",
    "\n",
    "    # Cluster composition heatmap\n",
    "    cluster_profiles = pd.DataFrame(data)\n",
    "    cluster_profiles['Cluster'] = clusters\n",
    "    summary = cluster_profiles.groupby('Cluster')[feature_cols].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(summary.applymap(float), annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "    plt.title(\"Cluster Centroids (Encoded)\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print centroids and return DataFrame\n",
    "    print(\"Cluster centroids:\")\n",
    "    print(km.cluster_centroids_)\n",
    "    return df\n",
    "\n",
    "kmode_analysis(bfrss_raw_df, DEMOGRAPHIC_FEATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Machine Learn Model to Predict Chronic Health Conditions from Demographics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def demographic_nn_prediction():\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
